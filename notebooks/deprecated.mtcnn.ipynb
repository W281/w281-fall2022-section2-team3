{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e05ecb6b-6bc4-402a-8883-3b0861313f45",
   "metadata": {},
   "source": [
    "# Face Identification Using MTCNN\n",
    "This notebook uses [MTCNN](https://github.com/ipazc/mtcnn) face detector.\n",
    "\n",
    "\n",
    "## Prerequesites\n",
    "Install the mtcnn library using\n",
    "```\n",
    "!pip install mtcnn\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c996b01f-382a-48de-8953-b3aeebc78f08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cbe4e25-42ca-4396-85df-f4c6513639e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-20 17:22:14.111698: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from mtcnn import MTCNN\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import preprocessor\n",
    "import configuration\n",
    "import glob\n",
    "import random\n",
    "import time\n",
    "import statistics\n",
    "import viz\n",
    "\n",
    "preproc = preprocessor.PreProcessor()\n",
    "config = configuration.Configuration()\n",
    "vizualizer = viz.Vizualizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0ba31e-875d-4ead-9894-77ac35ddb2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_face(model, image_file):\n",
    "    image = cv2.cvtColor(cv2.imread(image_file), cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "\n",
    "def extract_face_coords(model, image_file):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16095866-bec0-46b4-b727-6ae9a903a6d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def infer(ax, model, image_file):\n",
    "    # preparer = preprocessor.PreProcessor()\n",
    "    # image = preparer.increase_brightness(cv2.imread(image_file), 100)\n",
    "    # Sample prediction output:\n",
    "    # {\n",
    "    #     'box': [277, 90, 48, 63],\n",
    "    #     'keypoints':\n",
    "    #     {\n",
    "    #         'nose': (303, 131),\n",
    "    #         'mouth_right': (313, 141),\n",
    "    #         'right_eye': (314, 114),\n",
    "    #         'left_eye': (291, 117),\n",
    "    #         'mouth_left': (296, 143)\n",
    "    #     },\n",
    "    #     'confidence': 0.99851983785629272\n",
    "    # }\n",
    "    \n",
    "    image = cv2.cvtColor(cv2.imread(image_file), cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    start = time.process_time()\n",
    "    predictions = model.detect_faces(image)\n",
    "    time_taken = time.process_time() - start\n",
    "    for prediction in predictions:\n",
    "        bounding_box = prediction['box']\n",
    "        confidence = prediction['confidence']\n",
    "        if bounding_box:\n",
    "            if confidence <= 0.33:\n",
    "                edgecolor = 'yellow'\n",
    "            elif confidence <= 0.66:\n",
    "                edgecolor = 'orange'\n",
    "            else:\n",
    "                edgecolor = 'r'\n",
    "            [x,y,w,h] = bounding_box\n",
    "            rect = patches.Rectangle((x,y), w, h, linewidth=1, edgecolor=edgecolor, facecolor='none')\n",
    "            ax.add_patch(rect)\n",
    "\n",
    "        keypoints = prediction['keypoints']\n",
    "        if keypoints:\n",
    "            for point in keypoints.values():\n",
    "                ax.plot(point[0], point[1], marker=\"x\")\n",
    "        \n",
    "    ax.imshow(image, aspect='auto')\n",
    "    # ax.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    return time_taken\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a30242f0-5dcf-4b34-910c-47b231c4c760",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'device'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetal\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mMTCNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m times \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cur_class \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(config\u001b[38;5;241m.\u001b[39mclass_dict)):\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'device'"
     ]
    }
   ],
   "source": [
    "model = MTCNN()\n",
    "times = []\n",
    "for cur_class in range(len(config.class_dict)):\n",
    "    new_times = vizualizer.infer_and_plot(model, infer, \n",
    "                                          config.class_dict[cur_class], f'{config.IMAGES_BASE}/c{cur_class}', \n",
    "                                          num_images=1, cols=1) #, plt_width=14, plt_height=32)\n",
    "    times = [*times, *new_times]\n",
    "\n",
    "print(f'Average time for inference:{statistics.mean(times)} seconds')\n",
    "print(f'Anticipated preprocessing time for training dataset of 22,000:{22000 * statistics.mean(times) / 60} mins')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
