{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26076139-52b4-4aef-a8b8-3bbc0a66fa4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install hyperopt\n",
    "# !pip install -U tf_bodypix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1da199cf-f585-4f48-aba7-9dd68c35f6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc4f09a6-79fb-4181-8ec7-818f8f13a1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.__version__: 1.13.0\n",
      "tensor([1.], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yhkim/homebrew/anaconda3/lib/python3.9/site-packages/torch/_tensor_str.py:115: UserWarning: The operator 'aten::nonzero' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:11.)\n",
      "  nonzero_finite_vals = torch.masked_select(\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from enum import Enum, IntEnum\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from torchsummary import summary\n",
    "import torch\n",
    "print (f'torch.__version__: {torch.__version__}')\n",
    "import tensorflow as tf\n",
    "import cv2 as cv\n",
    "from torchvision import transforms\n",
    "import pickle\n",
    "\n",
    "import enums\n",
    "import viz\n",
    "import configuration\n",
    "import customdataset\n",
    "import transformers\n",
    "import models\n",
    "import feature_helpers\n",
    "from utilmethods import create_output_folders, check_torch_mps_device, make_torch_deterministic\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, validation_curve\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.stats import loguniform\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "check_torch_mps_device()\n",
    "device = 'cpu'\n",
    "device = 'mps'\n",
    "\n",
    "config = configuration.Configuration()\n",
    "face_config = configuration.FaceConfig(config)\n",
    "pose_config = configuration.PoseConfig(config)\n",
    "feature_extractor = feature_helpers.FeatureExtractor(config, face_config, pose_config, tqdm)\n",
    "\n",
    "LABELS_TO_INCLUDE = config.class_dict.keys()\n",
    "# LABELS_TO_INCLUDE=[0,1,2,9]\n",
    "\n",
    "IMAGE_TYPES = [enums.ImageTypes.ORIGINAL,enums.ImageTypes.POSE, enums.ImageTypes.FACE]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dee1b57-1b3e-49cb-ba70-1109afad2a40",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3364253f-4d78-449a-91ce-036ea10a0e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b5ec8197d4d4100b3c21938a024bcfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading 5400 samples:   0%|          | 0/5400 [00:00<?, ?samples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4494 samples.\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "data = feature_extractor.load_data(image_types=IMAGE_TYPES, labels=LABELS_TO_INCLUDE, shuffle=True, sample_type=enums.SampleType.TRAIN_VALIDATION,\n",
    "                                   count_per_label=540, include_feature_vectors=False)\n",
    "print(f'Loaded {data.shape[0]} samples.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eeaf77ef-acfa-42cf-8fbc-bec767522c98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "525bca7764084c3f9f5ef231b6f4d0dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading feature vectors:   0%|          | 0/4494 [00:00<?, ?images/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4494 samples with Index(['filename', 'label', 'original', 'pose', 'face'], dtype='object') columns.\n",
      "hog_features:(4494, 5776), hog_features.min:0.0, hog_features.max:1.0\n",
      "pixel_features:(4494, 25600), pixel_features.min:0.0, pixel_features.max:0.9999000430107117\n",
      "cnn_features:(4494, 2048), cnn_features.min:0.0, cnn_features.max:1.6100482940673828\n",
      "canny_features:(4494, 25600), canny_features.min:0, canny_features.max:255\n",
      "pose_features:(4494, 65536), pose_features.min:0.0, pose_features.max:0.6640035510063171\n",
      "keypoints_features:(4494, 26), keypoints_features.min:-0.48539406061172485, keypoints_features.max:0.9967774015857205\n",
      "rh_angles:(4494,), rh_angles.min:0.14272932927220916, rh_angles.max:357.43993703056964\n",
      "lh_angles:(4494,), lh_angles.min:6.315902309598239, lh_angles.max:358.8398645708594\n",
      "\n",
      "CPU times: user 3.03 s, sys: 2.08 s, total: 5.11 s\n",
      "Wall time: 9.78 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "all_features = feature_extractor.load_feature_vectors(config.FEATURE_VECTORS_FOLDER, data[enums.DataColumn.FILENAME.value], data[enums.DataColumn.LABEL.value])\n",
    "# pixel_features = data[enums.DataColumn.PIXEL_VECTOR.value].to_numpy()\n",
    "# hog_features = data[enums.DataColumn.HOG_VECTOR.value].to_numpy()\n",
    "# cnn_features = data[enums.DataColumn.CNN_VECTOR.value].to_numpy()\n",
    "# canny_features = data[enums.DataColumn.CANNY_VECTOR.value].to_numpy()\n",
    "# pose_features = data[enums.DataColumn.POSE_VECTOR.value].to_numpy()\n",
    "features_names = ['Pixel', 'Hog', 'CNN', 'Canny', 'Pose', 'Keypoints', ]\n",
    "[pixel_features, hog_features, cnn_features, canny_features, pose_features, keypoints_features, rh_angles, lh_angles] = all_features\n",
    "# Just keep cnn and keypoints_features as other features are too big.\n",
    "features_list = [keypoints_features]\n",
    "features_names = ['Keypoints']\n",
    "y = data[enums.DataColumn.LABEL.value]\n",
    "\n",
    "print(f'Loaded {data.shape[0]} samples with {data.columns} columns.')\n",
    "print(f'hog_features:{hog_features.shape}, hog_features.min:{np.min(hog_features)}, hog_features.max:{np.max(hog_features)}')\n",
    "print(f'pixel_features:{pixel_features.shape}, pixel_features.min:{np.min(pixel_features)}, pixel_features.max:{np.max(pixel_features)}')\n",
    "print(f'cnn_features:{cnn_features.shape}, cnn_features.min:{np.min(cnn_features)}, cnn_features.max:{np.max(cnn_features)}')\n",
    "print(f'canny_features:{canny_features.shape}, canny_features.min:{np.min(canny_features)}, canny_features.max:{np.max(canny_features)}')\n",
    "print(f'pose_features:{pose_features.shape}, pose_features.min:{np.min(pose_features)}, pose_features.max:{np.max(pose_features)}')\n",
    "print(f'keypoints_features:{keypoints_features.shape}, keypoints_features.min:{np.min(keypoints_features)}, keypoints_features.max:{np.max(keypoints_features)}')\n",
    "print(f'rh_angles:{rh_angles.shape}, rh_angles.min:{np.min(rh_angles)}, rh_angles.max:{np.max(rh_angles)}')\n",
    "print(f'lh_angles:{lh_angles.shape}, lh_angles.min:{np.min(lh_angles)}, lh_angles.max:{np.max(lh_angles)}')\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3380be1-213f-4c53-92e9-a4ba962520aa",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f36cac05-0698-4d20-a10b-3104651620a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers for vizualizing\n",
    "def plot_PCA(X_list, names, n_components=2, out_file='pca.jpg'):\n",
    "    pca_list, xpca_list = feature_extractor.get_PCA(X_list, n_components=n_components)\n",
    "    plt.figure(figsize=(15,5))\n",
    "    colors = ['b-', 'g-', 'r-', 'k-', 'y-']\n",
    "    plot_labels = [f'{name} features' for name in names]\n",
    "    for i in range(len(X_list)):\n",
    "        plt.plot(np.cumsum(pca_list[i].explained_variance_ratio_), colors[i], label=plot_labels[i])\n",
    "    plt.xticks(np.arange(n_components)+1)\n",
    "    plt.yticks(np.linspace(0, 1, 8))\n",
    "    plt.grid(visible=True)\n",
    "    plt.xlabel('Number of components')\n",
    "    plt.ylabel('Explained Variances')\n",
    "    plt.legend()\n",
    "    plt.tight_layout(pad=0.1, h_pad=None, w_pad=None, rect=None)\n",
    "    plt.savefig(f'{config.OUTPUT_FOLDER}/report_plots/{out_file}', dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "def plot_classes(X, y, ax, title, included_labels):\n",
    "    colormap = plt.cm.gist_rainbow # hsv tab20 #nipy_spectral #, Set1,Paired\n",
    "    colorst = [colormap(i) for i in np.linspace(0, 1.0, len(np.unique(y)))]\n",
    "    markers = ['o', 'v', 's', 'p', 'x', '>', '*', '<', 'P', '^']\n",
    "    for k, label in enumerate(included_labels):\n",
    "        marker = markers[k % len(markers)]\n",
    "        if X.shape[1] == 2:\n",
    "            ax.scatter(X[y==label, 0], X[y==label, 1], facecolors=colorst[k], marker=marker, label=config.class_dict[label])\n",
    "        else:\n",
    "            ax.scatter(X[y==label, 0], X[y==label, 1], X[y==label, 2], facecolors=colorst[k], marker=marker, label=config.class_dict[label])\n",
    "    ax.set_title(title)\n",
    "    \n",
    "def plot_components(features_list, X_pcas, X_tsnes, names, included_labels=LABELS_TO_INCLUDE, out_file='clustering.jpg'):\n",
    "    # project the features into 2 dimensions\n",
    "    fig, ax = plt.subplots(nrows=len(features_list), ncols=2, figsize=(10,5))\n",
    "    if len(features_list) == 1:\n",
    "        ax = [ax]\n",
    "\n",
    "    # y is the class labels\n",
    "    for i in range(len(features_list)):\n",
    "        plot_classes(X_pcas[i], y, ax[i][0], title=f'{names[i]} PCA', included_labels=LABELS_TO_INCLUDE)\n",
    "        plot_classes(X_tsnes[i], y, ax[i][1], title=f'{names[i]} tSNE', included_labels=LABELS_TO_INCLUDE)\n",
    "    \n",
    "    handles, plot_labels = ax[0][0].get_legend_handles_labels()\n",
    "    fig.legend(handles, plot_labels, loc='upper center')\n",
    "    plt.tight_layout(pad=0.1, h_pad=None, w_pad=12, rect=None)\n",
    "    plt.savefig(f'{config.OUTPUT_FOLDER}/report_plots/{out_file}', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cfc87ff-a58c-4dc4-b7f3-2b96c5170458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_list: 1\n",
      "(4494, 26)\n"
     ]
    }
   ],
   "source": [
    "print(f'features_list: {len(features_list)}')\n",
    "print(np.array(features_list[0]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49781460-eac2-4763-ba35-38ceaecd7b6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b09637391f6441b976f8e549f10a8bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Doing PCA(26):   0%|          | 0/1 [00:00<?, ?images/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.4 s, sys: 4.34 s, total: 23.8 s\n",
      "Wall time: 2.93 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "plot_PCA([features_list[0]], [features_names[0]], n_components=26, out_file=f'{features_names[0]}_pca.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7577fda5-e3dc-46d2-a31f-d7404e9db802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4494\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "print(len(features_list[0]))\n",
    "print(len(features_names[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "436292f4-5881-4520-a004-72784c2da81e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c55a7cbf936349efa12eed09f0dab958",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Doing PCA(2):   0%|          | 0/1 [00:00<?, ?images/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "585113da19c5485dad5cc31f6940b06f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Doing tSNE(2):   0%|          | 0/1 [00:00<?, ?images/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:9\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "File \u001b[0;32m<timed exec>:3\u001b[0m, in \u001b[0;36mvisualize_components\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/MIDS/w281/w281-fall2022-section2-team3/notebooks/feature_helpers.py:164\u001b[0m, in \u001b[0;36mFeatureExtractor.get_tsne\u001b[0;34m(self, X_list, n_components, perplexity)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m enumerator:\n\u001b[1;32m    162\u001b[0m     tsne \u001b[38;5;241m=\u001b[39m TSNE(n_components\u001b[38;5;241m=\u001b[39mn_components, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mSEED, \n\u001b[1;32m    163\u001b[0m         perplexity\u001b[38;5;241m=\u001b[39mperplexity, init\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpca\u001b[39m\u001b[38;5;124m'\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 164\u001b[0m     X_tsne \u001b[38;5;241m=\u001b[39m \u001b[43mtsne\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m     xtsne_list\u001b[38;5;241m.\u001b[39mappend(X_tsne)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xtsne_list\n",
      "File \u001b[0;32m~/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/manifold/_t_sne.py:1123\u001b[0m, in \u001b[0;36mTSNE.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;124;03m\"\"\"Fit X into an embedded space and return that transformed output.\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m \n\u001b[1;32m   1105\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;124;03m    Embedding of the training data in low-dimensional space.\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params_vs_input(X)\n\u001b[0;32m-> 1123\u001b[0m embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_ \u001b[38;5;241m=\u001b[39m embedding\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_\n",
      "File \u001b[0;32m~/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/manifold/_t_sne.py:962\u001b[0m, in \u001b[0;36mTSNE._fit\u001b[0;34m(self, X, skip_num_points)\u001b[0m\n\u001b[1;32m    955\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    956\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[t-SNE] Indexed \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m samples in \u001b[39m\u001b[38;5;132;01m{:.3f}\u001b[39;00m\u001b[38;5;124ms...\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    957\u001b[0m             n_samples, duration\n\u001b[1;32m    958\u001b[0m         )\n\u001b[1;32m    959\u001b[0m     )\n\u001b[1;32m    961\u001b[0m t0 \u001b[38;5;241m=\u001b[39m time()\n\u001b[0;32m--> 962\u001b[0m distances_nn \u001b[38;5;241m=\u001b[39m \u001b[43mknn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkneighbors_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdistance\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    963\u001b[0m duration \u001b[38;5;241m=\u001b[39m time() \u001b[38;5;241m-\u001b[39m t0\n\u001b[1;32m    964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n",
      "File \u001b[0;32m~/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_base.py:924\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors_graph\u001b[0;34m(self, X, n_neighbors, mode)\u001b[0m\n\u001b[1;32m    921\u001b[0m     A_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones(n_queries \u001b[38;5;241m*\u001b[39m n_neighbors)\n\u001b[1;32m    923\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistance\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 924\u001b[0m     A_data, A_ind \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_neighbors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    925\u001b[0m     A_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mravel(A_data)\n\u001b[1;32m    927\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_base.py:763\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    756\u001b[0m use_pairwise_distances_reductions \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    757\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbrute\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m PairwiseDistancesArgKmin\u001b[38;5;241m.\u001b[39mis_usable_for(\n\u001b[1;32m    759\u001b[0m         X \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meffective_metric_\n\u001b[1;32m    760\u001b[0m     )\n\u001b[1;32m    761\u001b[0m )\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_pairwise_distances_reductions:\n\u001b[0;32m--> 763\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mPairwiseDistancesArgKmin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    764\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    765\u001b[0m \u001b[43m        \u001b[49m\u001b[43mY\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_X\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    766\u001b[0m \u001b[43m        \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_neighbors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    767\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meffective_metric_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    768\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetric_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meffective_metric_params_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    769\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_distance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    773\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[1;32m    774\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbrute\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecomputed\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m issparse(X)\n\u001b[1;32m    775\u001b[0m ):\n\u001b[1;32m    776\u001b[0m     results \u001b[38;5;241m=\u001b[39m _kneighbors_from_graph(\n\u001b[1;32m    777\u001b[0m         X, n_neighbors\u001b[38;5;241m=\u001b[39mn_neighbors, return_distance\u001b[38;5;241m=\u001b[39mreturn_distance\n\u001b[1;32m    778\u001b[0m     )\n",
      "File \u001b[0;32msklearn/metrics/_pairwise_distances_reduction.pyx:698\u001b[0m, in \u001b[0;36msklearn.metrics._pairwise_distances_reduction.PairwiseDistancesArgKmin.compute\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py:151\u001b[0m, in \u001b[0;36mthreadpool_limits\u001b[0;34m(limits, user_api)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m controller\u001b[38;5;241m.\u001b[39mlimit(limits\u001b[38;5;241m=\u001b[39mlimits, user_api\u001b[38;5;241m=\u001b[39muser_api)\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mthreadpoolctl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthreadpool_limits\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlimits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_api\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_api\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/homebrew/anaconda3/lib/python3.9/site-packages/threadpoolctl.py:171\u001b[0m, in \u001b[0;36mthreadpool_limits.__init__\u001b[0;34m(self, limits, user_api)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, limits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, user_api\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_limits, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_user_api, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prefixes \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m    169\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params(limits, user_api)\n\u001b[0;32m--> 171\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_threadpool_limits\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/homebrew/anaconda3/lib/python3.9/site-packages/threadpoolctl.py:268\u001b[0m, in \u001b[0;36mthreadpool_limits._set_threadpool_limits\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_limits \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 268\u001b[0m modules \u001b[38;5;241m=\u001b[39m \u001b[43m_ThreadpoolInfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprefixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prefixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m                          \u001b[49m\u001b[43muser_api\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_user_api\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;66;03m# self._limits is a dict {key: num_threads} where key is either\u001b[39;00m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;66;03m# a prefix or a user_api. If a module matches both, the limit\u001b[39;00m\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;66;03m# corresponding to the prefix is chosed.\u001b[39;00m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module\u001b[38;5;241m.\u001b[39mprefix \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_limits:\n",
      "File \u001b[0;32m~/homebrew/anaconda3/lib/python3.9/site-packages/threadpoolctl.py:340\u001b[0m, in \u001b[0;36m_ThreadpoolInfo.__init__\u001b[0;34m(self, user_api, prefixes, modules)\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_api \u001b[38;5;241m=\u001b[39m [] \u001b[38;5;28;01mif\u001b[39;00m user_api \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m user_api\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodules \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 340\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_modules\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warn_if_incompatible_openmp()\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/homebrew/anaconda3/lib/python3.9/site-packages/threadpoolctl.py:371\u001b[0m, in \u001b[0;36m_ThreadpoolInfo._load_modules\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;124;03m\"\"\"Loop through loaded libraries and store supported ones\"\"\"\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mplatform \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdarwin\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 371\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_find_modules_with_dyld\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mplatform \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwin32\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_find_modules_with_enum_process_module_ex()\n",
      "File \u001b[0;32m~/homebrew/anaconda3/lib/python3.9/site-packages/threadpoolctl.py:428\u001b[0m, in \u001b[0;36m_ThreadpoolInfo._find_modules_with_dyld\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    425\u001b[0m filepath \u001b[38;5;241m=\u001b[39m filepath\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    427\u001b[0m \u001b[38;5;66;03m# Store the module if it is supported and selected\u001b[39;00m\n\u001b[0;32m--> 428\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_module_from_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/homebrew/anaconda3/lib/python3.9/site-packages/threadpoolctl.py:515\u001b[0m, in \u001b[0;36m_ThreadpoolInfo._make_module_from_path\u001b[0;34m(self, filepath)\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prefix \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprefixes \u001b[38;5;129;01mor\u001b[39;00m user_api \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_api:\n\u001b[1;32m    514\u001b[0m     module_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mglobals\u001b[39m()[module_class]\n\u001b[0;32m--> 515\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[43mmodule_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_api\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minternal_api\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodules\u001b[38;5;241m.\u001b[39mappend(module)\n",
      "File \u001b[0;32m~/homebrew/anaconda3/lib/python3.9/site-packages/threadpoolctl.py:606\u001b[0m, in \u001b[0;36m_Module.__init__\u001b[0;34m(self, filepath, prefix, user_api, internal_api)\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minternal_api \u001b[38;5;241m=\u001b[39m internal_api\n\u001b[1;32m    605\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dynlib \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mCDLL(filepath, mode\u001b[38;5;241m=\u001b[39m_RTLD_NOLOAD)\n\u001b[0;32m--> 606\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mversion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_version\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_threads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_num_threads()\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_extra_info()\n",
      "File \u001b[0;32m~/homebrew/anaconda3/lib/python3.9/site-packages/threadpoolctl.py:646\u001b[0m, in \u001b[0;36m_OpenBLASModule.get_version\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    643\u001b[0m get_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dynlib, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenblas_get_config\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    644\u001b[0m                      \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    645\u001b[0m get_config\u001b[38;5;241m.\u001b[39mrestype \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mc_char_p\n\u001b[0;32m--> 646\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[43mget_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m()\n\u001b[1;32m    647\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOpenBLAS\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m config[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def visualize_components():\n",
    "    pcas = feature_extractor.get_PCA(features_list, n_components=2)[-1]\n",
    "    tsnes = feature_extractor.get_tsne(features_list, n_components=2)\n",
    "    plot_components(features_list, \n",
    "                    pcas, \n",
    "                    tsnes,\n",
    "                    features_names,\n",
    "                    included_labels=LABELS_TO_INCLUDE)\n",
    "visualize_components()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020e2033-7239-4425-a763-a624cf4f0c66",
   "metadata": {},
   "source": [
    "## KNN Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ada30c0-38e2-4aae-b128-049e9f1e064f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load feature vectors\n",
    "[pixel_features, hog_features, cnn_features, canny_features, pose_features] = feature_extractor.load_feature_vectors(config.FEATURE_VECTORS_FOLDER, data['filename'], data['label'])\n",
    "X_pixels_pca, X_hog_pca, X_CNN_pca, X_canny_pca, X_pose_pca = feature_extractor.get_PCA(features_list, n_components=2)[-1]\n",
    "X_pixels_tsne, X_hog_tsne, X_CNN_tsne, X_canny_tsne, X_pose_tsne = feature_extractor.get_tsne(features_list, n_components=2)\n",
    "y = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9524c591-3aed-4a0b-88bc-d604dc8c23f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(knn, pca, y, idx):\n",
    "    knn.fit(pca, y)\n",
    "    accuracy = 0\n",
    "    for i in idx:\n",
    "        label = knn.predict([pca[i,:]])\n",
    "        if label[0] == y[i]:\n",
    "            accuracy +=1\n",
    "    return accuracy\n",
    "\n",
    "def accuracies(n_samples):\n",
    "    knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "    idx = np.random.choice(np.arange(len(y)), n_samples, replace=False)\n",
    "    # print(y[idx])\n",
    "    print(f'Accuracies from {n_samples} samples:')\n",
    "    print('Pixel PCA Accuracy: ', calc_accuracy(knn, X_pixels_pca, y, idx)/n_samples)\n",
    "    print('Pixel tSNE Accuracy: ', calc_accuracy(knn, X_pixels_tsne, y, idx)/n_samples)\n",
    "    print('HOG PCA Accuracy: ', calc_accuracy(knn, X_hog_pca, y, idx)/n_samples)\n",
    "    print('HOG tSNE Accuracy: ', calc_accuracy(knn, X_hog_tsne, y, idx)/n_samples)\n",
    "    print('CNN PCA Accuracy: ', calc_accuracy(knn, X_CNN_pca, y, idx)/n_samples)\n",
    "    print('CNN tSNE Accuracy: ', calc_accuracy(knn, X_CNN_tsne, y, idx)/n_samples)\n",
    "    print('Canny PCA Accuracy: ', calc_accuracy(knn, X_canny_pca, y, idx)/n_samples)\n",
    "    print('Canny tSNE Accuracy: ', calc_accuracy(knn, X_canny_tsne, y, idx)/n_samples)\n",
    "    print('Pose PCA Accuracy: ', calc_accuracy(knn, X_pose_pca, y, idx)/n_samples)\n",
    "    print('Pose tSNE Accuracy: ', calc_accuracy(knn, X_pose_tsne, y, idx)/n_samples)\n",
    "\n",
    "print(f'Loaded {data.shape[0]} samples.')\n",
    "print(f'hog_features:{hog_features.shape}, hog_features.min:{np.min(hog_features)}, hog_features.max:{np.max(hog_features)}')\n",
    "print(f'pixel_features:{pixel_features.shape}, pixel_features.min:{np.min(pixel_features)}, pixel_features.max:{np.max(pixel_features)}')\n",
    "print(f'cnn_features:{cnn_features.shape}, cnn_features.min:{np.min(cnn_features)}, cnn_features.max:{np.max(cnn_features)}')\n",
    "print(f'canny_features:{canny_features.shape}, canny_features.min:{np.min(canny_features)}, canny_features.max:{np.max(canny_features)}')\n",
    "print(f'pose_features:{pose_features.shape}, pose_features.min:{np.min(pose_features)}, pose_features.max:{np.max(pose_features)}')\n",
    "print()\n",
    "accuracies(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa1d5ea-ab5d-4d5d-a862-cd3f83c3dc55",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d022e6bd-2270-4cc7-8ab7-32d8448e91ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the train and test split\n",
    "[pixel_features, hog_features, cnn_features, canny_features, pose_features] = feature_extractor.load_feature_vectors(config.FEATURE_VECTORS_FOLDER, data['filename'], data['label'])\n",
    "train_idx, val_idx = train_test_split(np.arange(len(y)), test_size=0.2, random_state=config.SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "713e307b-759e-4588-910b-99d4d95af6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import STATUS_OK,rand, tpe, Trials, fmin, hp\n",
    "from hyperopt.early_stop import no_progress_loss\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Input dict for hypteropt\n",
    "opt_dict = {\n",
    "    # 'logistic_regression': {\n",
    "    #     'model': LogisticRegression,\n",
    "    #     'params': {\n",
    "    #         'penalty': 'l1',\n",
    "    #         'solver': 'saga',\n",
    "    #         'max_iter': 5000,\n",
    "    #         'C': hp.loguniform('C', 1e-3, 1e5)\n",
    "    #     }\n",
    "    # },\n",
    "    'random_forest': {\n",
    "        'model': RandomForestClassifier,\n",
    "        'params': {\n",
    "                'max_depth': 2 + hp.randint('max_depth', 20),\n",
    "                'n_estimators': 2 + hp.randint('n_estimators', 300),\n",
    "                'n_jobs': 4\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Optimizer definition\n",
    "def optimize(opt_dict, best_dict, X_train, y_train, max_evals = 50, random_state = config.SEED):\n",
    "    \"\"\"\n",
    "        Runs hyperopt for all the models in opt_dict. Adds the best hyperparameter set for each model.\n",
    "        Returns dictionary of best hyperparameter set.\n",
    "    \"\"\"\n",
    "    # Define TPE algorithm for all optimizers\n",
    "    tpe_algo = tpe.suggest\n",
    "\n",
    "    # Iterate over opt_dict\n",
    "    for k,v in opt_dict.items():\n",
    "        ## Attributes\n",
    "        model_name = k\n",
    "        model = v['model']\n",
    "        params = v['params']\n",
    "\n",
    "        ## objective function definition\n",
    "        def f(params):\n",
    "            loss = None\n",
    "            try:\n",
    "                m = model(random_state = random_state, **params)\n",
    "                loss = cross_val_score(m, X_train, y_train, scoring = 'neg_log_loss').mean()\n",
    "            except: AttributeError\n",
    "\n",
    "            return {'loss': -loss, 'status': STATUS_OK}\n",
    "\n",
    "        ## Define trial space\n",
    "        trials = Trials()\n",
    "\n",
    "        print(f\"Optimizing {k} model...\")\n",
    "\n",
    "        ## optimize\n",
    "        best = fmin(\n",
    "            fn = f,\n",
    "            space = params,\n",
    "            algo = tpe_algo,\n",
    "            max_evals = max_evals,\n",
    "            trials = trials,\n",
    "            early_stop_fn=no_progress_loss(1e-10)\n",
    "        )\n",
    "\n",
    "        best_dict[model_name] = best\n",
    "        print(f\"Best hyperparameter set for {model_name} is {best}\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "    return best_dict\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# X_train = pose_features[train_idx, :].copy()\n",
    "# y_train = y[train_idx].copy()\n",
    "# X_val = pose_features[val_idx, :].copy()\n",
    "# y_val = y[val_idx].copy()\n",
    "\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_val = scaler.fit_transform(X_val)\n",
    "\n",
    "# # Optimize and output best hyperparameter set for each model\n",
    "# best_dict = optimize(opt_dict = opt_dict,\n",
    "#                      best_dict = best_dict,\n",
    "#                      X_train = X_train,\n",
    "#                      y_train = y_train,\n",
    "#                      max_evals = 100)\n",
    "# best_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3ada64e0-94f3-463c-8f98-fdbcbc961c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'random_forest': {'max_depth': 0, 'n_estimators': 17}}\n",
    "# clf = RandomForestClassifier(random_state = config.SEED, n_jobs = 4, max_depth = 1, n_estimators = 3)\n",
    "# clf.fit(X_train, y_train)\n",
    "# y_pred = clf.predict(X_val)\n",
    "# accuracy_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "44e68196-ec5e-4031-9dc2-5661e4e615a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(in_feat, in_y, in_train_idx, val_idx):\n",
    "    # get the train and validation split\n",
    "    X_train = in_feat[in_train_idx, :].copy()\n",
    "    y_train = in_y[in_train_idx].copy()\n",
    "    X_val = in_feat[val_idx, :].copy()\n",
    "    y_val = in_y[val_idx].copy()\n",
    "\n",
    "    # scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_val = scaler.transform(X_val)\n",
    "\n",
    "    # classifier with cross validation\n",
    "    best_dict = {}\n",
    "    param_grid = {\n",
    "        'logistic_regression': {\n",
    "            'model': LogisticRegression,\n",
    "            'params': {\n",
    "                'penalty': 'elasticnet',\n",
    "                'solver': 'saga',\n",
    "                'max_iter': 5000,\n",
    "                'C': hp.loguniform('C', 50, 200),\n",
    "                'l1_ratio': hp.loguniform(0.3, 0.9)\n",
    "            }\n",
    "        },\n",
    "        'random_forest': {\n",
    "            'model': RandomForestClassifier,\n",
    "            'params': {\n",
    "                    'max_depth': 1 + hp.randint('max_depth', 20),\n",
    "                    'n_estimators': 1 + hp.randint('n_estimators', 300),\n",
    "                    'n_jobs': 4\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    # Optimize and output best hyperparameter set for each model\n",
    "    best_dict = optimize(opt_dict = param_grid,\n",
    "                         best_dict = best_dict,\n",
    "                         X_train = X_train,\n",
    "                         y_train = y_train,\n",
    "                         max_evals = 100)\n",
    "    clf_lr = LogisticRegression()\n",
    "    clf_rf = RandomForestClassifier(random_state = config.SEED, **best_dict['random_forest'])\n",
    "    clf_rf = clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_val)\n",
    "\n",
    "    return accuracy_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50511390-7307-484f-82b6-be14918b102f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['max_error', 'min_error']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = ['max_error', 'min_error', 'hello']\n",
    "[x for x in a if 'error' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "60bbad6f-e56f-453c-a53b-b084d366a3e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd9aa67f2f2643098c17c87d94b9c6d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Doing PCA(50):   0%|          | 0/1000 [00:00<?, ?images/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "X_list = pose_features\n",
    "enumerator = X_list if tqdm is None else tqdm(X_list, unit='images', desc=f'Doing PCA({50})')\n",
    "ct = 0\n",
    "\n",
    "for X in enumerator:\n",
    "    ct += 1\n",
    "print(ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "aac30a80-92f1-4b2c-bb9c-9cec59fdad75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pose Feature Accuracy\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afcaa3f1b27c4446862b2611d27de45c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pose:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25dd5c21623b49908df4c94b4bc11da4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Doing PCA(51):   0%|          | 0/1 [00:00<?, ?images/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing random_forest model...\n",
      "\n",
      "  0%|                                                                                                               | 0/100 [00:00<?, ?trial/s, best loss=?]\u001b[A\n",
      "  1%|                                                                                    | 1/100 [00:01<01:55,  1.16s/trial, best loss: 1.6997333459869792]\u001b[A\n",
      "  2%|                                                                                   | 2/100 [00:01<01:04,  1.51trial/s, best loss: 1.6997333459869792]\u001b[A\n",
      "  3%|                                                                                  | 3/100 [00:02<01:10,  1.38trial/s, best loss: 1.6961244481184934]\u001b[A\n",
      "  4%|                                                                                 | 4/100 [00:02<01:04,  1.48trial/s, best loss: 1.6961244481184934]\u001b[A\n",
      "  5%|                                                                                | 5/100 [00:03<00:55,  1.70trial/s, best loss: 1.6961244481184934]\u001b[A\n",
      "  6%|                                                                                | 6/100 [00:03<00:44,  2.11trial/s, best loss: 1.6961244481184934]\u001b[A\n",
      "  7%|                                                                               | 7/100 [00:03<00:35,  2.65trial/s, best loss: 1.6961244481184934]\u001b[A\n",
      "  8%|                                                                              | 8/100 [00:04<01:00,  1.53trial/s, best loss: 1.6951678185075276]\u001b[A\n",
      "  9%|                                                                             | 9/100 [00:05<00:50,  1.79trial/s, best loss: 1.6951678185075276]\u001b[A\n",
      " 10%|                                                                           | 10/100 [00:06<00:54,  1.65trial/s, best loss: 1.6951678185075276]\u001b[A\n",
      " 11%|                                                                          | 11/100 [00:07<01:08,  1.30trial/s, best loss: 1.6951678185075276]\u001b[A\n",
      " 12%|                                                                          | 12/100 [00:08<01:13,  1.20trial/s, best loss: 1.6951678185075276]\u001b[A\n",
      " 13%|                                                                         | 13/100 [00:09<01:17,  1.12trial/s, best loss: 1.6951678185075276]\u001b[A\n",
      " 14%|                                                                        | 14/100 [00:09<01:03,  1.36trial/s, best loss: 1.6951678185075276]\u001b[A\n",
      " 15%|                                                                       | 15/100 [00:09<00:53,  1.60trial/s, best loss: 1.6951678185075276]\u001b[A\n",
      " 16%|                                                                      | 16/100 [00:10<00:48,  1.72trial/s, best loss: 1.6951678185075276]\u001b[A\n",
      " 17%|                                                                     | 17/100 [00:11<00:53,  1.55trial/s, best loss: 1.6951678185075276]\u001b[A\n",
      " 18%|                                                                     | 18/100 [00:12<00:58,  1.39trial/s, best loss: 1.6951678185075276]\u001b[A\n",
      " 19%|                                                                    | 19/100 [00:12<00:49,  1.63trial/s, best loss: 1.6951678185075276]\u001b[A\n",
      " 20%|                                                                   | 20/100 [00:12<00:37,  2.11trial/s, best loss: 1.6951678185075276]\u001b[A\n",
      " 21%|                                                                  | 21/100 [00:13<00:49,  1.60trial/s, best loss: 1.6951678185075276]\u001b[A\n",
      " 22%|                                                                 | 22/100 [00:14<00:46,  1.67trial/s, best loss: 1.6951678185075276]\u001b[A\n",
      " 23%|                                                                | 23/100 [00:14<00:49,  1.55trial/s, best loss: 1.6951678185075276]\u001b[A\n",
      " 24%|                                                               | 24/100 [00:15<00:46,  1.64trial/s, best loss: 1.6951678185075276]\u001b[A\n",
      " 25%|                                                               | 25/100 [00:15<00:41,  1.81trial/s, best loss: 1.6951678185075276]\u001b[A\n",
      " 26%|                                                              | 26/100 [00:16<00:36,  2.00trial/s, best loss: 1.6951678185075276]\u001b[A\n",
      " 27%|                                                             | 27/100 [00:16<00:38,  1.89trial/s, best loss: 1.6951678185075276]\u001b[A\n",
      " 28%|                                                            | 28/100 [00:17<00:42,  1.71trial/s, best loss: 1.6951678185075276]\u001b[A\n",
      " 29%|                                                           | 29/100 [00:18<00:49,  1.43trial/s, best loss: 1.6951678185075276]\u001b[A\n",
      " 30%|                                                          | 30/100 [00:18<00:39,  1.77trial/s, best loss: 1.6951678185075276]\u001b[A\n",
      " 31%|                                                          | 31/100 [00:18<00:32,  2.12trial/s, best loss: 1.6951678185075276]\u001b[A\n",
      " 32%|                                                         | 32/100 [00:19<00:25,  2.65trial/s, best loss: 1.6951678185075276]\u001b[A\n",
      " 34%|                                                       | 34/100 [00:19<00:19,  3.46trial/s, best loss: 1.6951678185075276]\u001b[A\n",
      " 35%|                                                      | 35/100 [00:20<00:27,  2.35trial/s, best loss: 1.6951678185075276]\u001b[A\n",
      " 36%|                                                     | 36/100 [00:21<00:36,  1.76trial/s, best loss: 1.6906106713091025]\u001b[A\n",
      " 37%|                                                     | 37/100 [00:21<00:30,  2.08trial/s, best loss: 1.6906106713091025]\u001b[A\n",
      " 39%|                                                   | 39/100 [00:22<00:29,  2.10trial/s, best loss: 1.6906106713091025]\u001b[A\n",
      " 40%|                                                  | 40/100 [00:22<00:27,  2.17trial/s, best loss: 1.6906106713091025]\u001b[A\n",
      " 41%|                                                 | 41/100 [00:23<00:22,  2.68trial/s, best loss: 1.6906106713091025]\u001b[A\n",
      " 42%|                                                | 42/100 [00:23<00:27,  2.15trial/s, best loss: 1.6906106713091025]\u001b[A\n",
      " 43%|                                                | 43/100 [00:24<00:29,  1.90trial/s, best loss: 1.6906106713091025]\u001b[A\n",
      " 44%|                                               | 44/100 [00:25<00:34,  1.61trial/s, best loss: 1.6906106713091025]\u001b[A\n",
      " 45%|                                              | 45/100 [00:26<00:35,  1.55trial/s, best loss: 1.6906106713091025]\u001b[A\n",
      " 46%|                                             | 46/100 [00:26<00:32,  1.67trial/s, best loss: 1.6906106713091025]\u001b[A\n",
      " 47%|                                            | 47/100 [00:26<00:29,  1.80trial/s, best loss: 1.6906106713091025]\u001b[A\n",
      " 48%|                                           | 48/100 [00:27<00:25,  2.05trial/s, best loss: 1.6906106713091025]\u001b[A\n",
      " 49%|                                          | 49/100 [00:27<00:19,  2.56trial/s, best loss: 1.6906106713091025]\u001b[A\n",
      " 50%|                                          | 50/100 [00:28<00:23,  2.12trial/s, best loss: 1.6906106713091025]\u001b[A\n",
      " 51%|                                         | 51/100 [00:28<00:21,  2.33trial/s, best loss: 1.6906106713091025]\u001b[A\n",
      " 53%|                                       | 53/100 [00:28<00:14,  3.16trial/s, best loss: 1.6906106713091025]\u001b[A\n",
      " 54%|                                      | 54/100 [00:29<00:14,  3.14trial/s, best loss: 1.6906106713091025]\u001b[A\n",
      " 55%|                                     | 55/100 [00:29<00:18,  2.48trial/s, best loss: 1.6906106713091025]\u001b[A\n",
      " 56%|                                     | 56/100 [00:30<00:24,  1.83trial/s, best loss: 1.6906106713091025]\u001b[A\n",
      " 57%|                                    | 57/100 [00:31<00:23,  1.80trial/s, best loss: 1.6906106713091025]\u001b[A\n",
      " 58%|                                   | 58/100 [00:31<00:20,  2.06trial/s, best loss: 1.6906106713091025]\u001b[A\n",
      " 59%|                                  | 59/100 [00:32<00:21,  1.95trial/s, best loss: 1.6906106713091025]\u001b[A\n",
      " 60%|                                 | 60/100 [00:32<00:22,  1.81trial/s, best loss: 1.6906106713091025]\u001b[A\n",
      " 61%|                                | 61/100 [00:33<00:25,  1.53trial/s, best loss: 1.6906106713091025]\u001b[A\n",
      " 62%|                                | 62/100 [00:34<00:21,  1.77trial/s, best loss: 1.6906106713091025]\u001b[A\n",
      " 63%|                               | 63/100 [00:34<00:24,  1.52trial/s, best loss: 1.6906106713091025]\u001b[A\n",
      " 64%|                              | 64/100 [00:35<00:24,  1.46trial/s, best loss: 1.6906106713091025]\u001b[A\n",
      " 65%|                             | 65/100 [00:36<00:20,  1.73trial/s, best loss: 1.6906106713091025]\u001b[A\n",
      " 66%|                            | 66/100 [00:37<00:25,  1.33trial/s, best loss: 1.6906106713091025]\u001b[A\n",
      " 67%|                           | 67/100 [00:38<00:26,  1.25trial/s, best loss: 1.6906106713091025]\u001b[A\n",
      " 68%|                           | 68/100 [00:38<00:19,  1.60trial/s, best loss: 1.6906106713091025]\u001b[A\n",
      " 69%|                          | 69/100 [00:38<00:18,  1.71trial/s, best loss: 1.6906106713091025]\u001b[A\n",
      " 70%|                         | 70/100 [00:39<00:14,  2.08trial/s, best loss: 1.6906106713091025]\u001b[A\n",
      " 71%|                        | 71/100 [00:39<00:16,  1.76trial/s, best loss: 1.6906106713091025]\u001b[A\n",
      " 72%|                       | 72/100 [00:40<00:19,  1.42trial/s, best loss: 1.6888076917228052]\u001b[A\n",
      " 73%|                       | 73/100 [00:41<00:21,  1.23trial/s, best loss: 1.68808179935233]\u001b[A\n",
      " 74%|                      | 74/100 [00:42<00:22,  1.18trial/s, best loss: 1.686743365631886]\u001b[A\n",
      " 75%|                     | 75/100 [00:43<00:22,  1.11trial/s, best loss: 1.686743365631886]\u001b[A\n",
      " 76%|                    | 76/100 [00:44<00:16,  1.46trial/s, best loss: 1.686743365631886]\u001b[A\n",
      " 77%|                   | 77/100 [00:44<00:15,  1.47trial/s, best loss: 1.686743365631886]\u001b[A\n",
      " 78%|                  | 78/100 [00:45<00:12,  1.74trial/s, best loss: 1.686743365631886]\u001b[A\n",
      " 79%|                 | 79/100 [00:46<00:15,  1.36trial/s, best loss: 1.686743365631886]\u001b[A\n",
      " 80%|                 | 80/100 [00:46<00:11,  1.81trial/s, best loss: 1.686743365631886]\u001b[A\n",
      " 81%|                | 81/100 [00:47<00:11,  1.62trial/s, best loss: 1.6864709539043723]\u001b[A\n",
      " 82%|               | 82/100 [00:48<00:14,  1.28trial/s, best loss: 1.6864709539043723]\u001b[A\n",
      " 83%|              | 83/100 [00:48<00:13,  1.29trial/s, best loss: 1.6864709539043723]\u001b[A\n",
      " 84%|             | 84/100 [00:49<00:10,  1.47trial/s, best loss: 1.6864709539043723]\u001b[A\n",
      " 85%|            | 85/100 [00:50<00:11,  1.31trial/s, best loss: 1.6864709539043723]\u001b[A\n",
      " 86%|           | 86/100 [00:50<00:08,  1.73trial/s, best loss: 1.6864709539043723]\u001b[A\n",
      " 87%|           | 87/100 [00:50<00:06,  2.09trial/s, best loss: 1.6864709539043723]\u001b[A\n",
      " 88%|          | 88/100 [00:51<00:05,  2.30trial/s, best loss: 1.6864709539043723]\u001b[A\n",
      " 89%|         | 89/100 [00:51<00:04,  2.22trial/s, best loss: 1.6864709539043723]\u001b[A\n",
      " 90%|        | 90/100 [00:52<00:04,  2.20trial/s, best loss: 1.6864709539043723]\u001b[A\n",
      " 91%|       | 91/100 [00:52<00:03,  2.78trial/s, best loss: 1.6864709539043723]\u001b[A\n",
      " 92%|      | 92/100 [00:52<00:03,  2.27trial/s, best loss: 1.6864709539043723]\u001b[A\n",
      " 93%|      | 93/100 [00:53<00:03,  2.23trial/s, best loss: 1.6864709539043723]\u001b[A\n",
      " 94%|     | 94/100 [00:53<00:03,  1.96trial/s, best loss: 1.6864709539043723]\u001b[A\n",
      " 95%|    | 95/100 [00:55<00:03,  1.48trial/s, best loss: 1.6864709539043723]\u001b[A\n",
      " 96%|   | 96/100 [00:55<00:02,  1.84trial/s, best loss: 1.6864709539043723]\u001b[A\n",
      " 97%|  | 97/100 [00:56<00:01,  1.60trial/s, best loss: 1.6864709539043723]\u001b[A\n",
      " 98%| | 98/100 [00:56<00:01,  1.93trial/s, best loss: 1.6864709539043723]\u001b[A\n",
      " 99%|| 99/100 [00:57<00:00,  1.70trial/s, best loss: 1.6864709539043723]\u001b[A\n",
      "100%|| 100/100 [00:57<00:00,  1.73trial/s, best loss: 1.6864709539043723]\u001b[A\n",
      "Best hyperparameter set for random_forest is {'max_depth': 13, 'n_estimators': 196}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0549c6692794906a51d15819eb33d42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Doing PCA(101):   0%|          | 0/1 [00:00<?, ?images/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing random_forest model...\n",
      "\n",
      "  0%|                                                                                                               | 0/100 [00:00<?, ?trial/s, best loss=?]\u001b[A\n",
      "  1%|                                                                                     | 1/100 [00:00<00:20,  4.78trial/s, best loss: 5.480217295189005]\u001b[A\n",
      "  2%|                                                                                     | 2/100 [00:00<00:34,  2.81trial/s, best loss: 1.80168286527506]\u001b[A\n",
      "  3%|                                                                                   | 3/100 [00:02<01:23,  1.17trial/s, best loss: 1.786406684558776]\u001b[A\n",
      "  4%|                                                                                 | 4/100 [00:03<01:32,  1.04trial/s, best loss: 1.7814188986549222]\u001b[A\n",
      "  5%|                                                                                | 5/100 [00:03<01:16,  1.24trial/s, best loss: 1.7814188986549222]\u001b[A\n",
      "  6%|                                                                                | 6/100 [00:04<01:09,  1.36trial/s, best loss: 1.7814188986549222]\u001b[A\n",
      "  7%|                                                                               | 7/100 [00:04<00:51,  1.80trial/s, best loss: 1.7814188986549222]\u001b[A\n",
      "  8%|                                                                              | 8/100 [00:05<00:51,  1.78trial/s, best loss: 1.7814188986549222]\u001b[A\n",
      "  9%|                                                                             | 9/100 [00:06<01:08,  1.32trial/s, best loss: 1.7814188986549222]\u001b[A\n",
      " 10%|                                                                           | 10/100 [00:07<01:21,  1.11trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 11%|                                                                          | 11/100 [00:08<01:09,  1.28trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 12%|                                                                          | 12/100 [00:09<01:17,  1.13trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 13%|                                                                         | 13/100 [00:09<01:09,  1.25trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 14%|                                                                        | 14/100 [00:10<01:09,  1.24trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 15%|                                                                       | 15/100 [00:11<01:03,  1.34trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 16%|                                                                      | 16/100 [00:11<00:57,  1.45trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 17%|                                                                     | 17/100 [00:12<01:06,  1.26trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 19%|                                                                    | 19/100 [00:14<00:57,  1.42trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 20%|                                                                   | 20/100 [00:15<01:07,  1.19trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 21%|                                                                  | 21/100 [00:16<01:10,  1.12trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 22%|                                                                 | 22/100 [00:16<00:57,  1.35trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 23%|                                                                | 23/100 [00:17<01:01,  1.25trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 24%|                                                               | 24/100 [00:17<00:48,  1.56trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 25%|                                                               | 25/100 [00:18<00:58,  1.27trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 26%|                                                              | 26/100 [00:19<00:56,  1.32trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 27%|                                                             | 27/100 [00:20<00:55,  1.32trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 28%|                                                            | 28/100 [00:22<01:15,  1.05s/trial, best loss: 1.7796852055007588]\u001b[A\n",
      " 29%|                                                           | 29/100 [00:22<00:59,  1.20trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 30%|                                                          | 30/100 [00:23<00:53,  1.30trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 31%|                                                          | 31/100 [00:23<00:52,  1.31trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 32%|                                                         | 32/100 [00:25<01:02,  1.09trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 33%|                                                        | 33/100 [00:26<01:07,  1.01s/trial, best loss: 1.7796852055007588]\u001b[A\n",
      " 34%|                                                       | 34/100 [00:27<01:10,  1.07s/trial, best loss: 1.7796852055007588]\u001b[A\n",
      " 35%|                                                      | 35/100 [00:28<01:12,  1.11s/trial, best loss: 1.7796852055007588]\u001b[A\n",
      " 36%|                                                     | 36/100 [00:29<00:57,  1.11trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 37%|                                                     | 37/100 [00:29<00:52,  1.20trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 38%|                                                    | 38/100 [00:31<01:01,  1.00trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 39%|                                                   | 39/100 [00:31<00:54,  1.13trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 40%|                                                  | 40/100 [00:32<00:52,  1.15trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 41%|                                                 | 41/100 [00:33<00:53,  1.11trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 42%|                                                | 42/100 [00:33<00:38,  1.51trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 43%|                                                | 43/100 [00:34<00:40,  1.42trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 44%|                                               | 44/100 [00:35<00:35,  1.58trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 45%|                                              | 45/100 [00:35<00:28,  1.95trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 46%|                                             | 46/100 [00:36<00:36,  1.50trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 47%|                                            | 47/100 [00:36<00:33,  1.59trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 48%|                                           | 48/100 [00:37<00:26,  1.95trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 49%|                                          | 49/100 [00:38<00:33,  1.54trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 50%|                                          | 50/100 [00:39<00:44,  1.13trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 51%|                                         | 51/100 [00:40<00:45,  1.08trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 52%|                                        | 52/100 [00:41<00:48,  1.01s/trial, best loss: 1.7796852055007588]\u001b[A\n",
      " 53%|                                       | 53/100 [00:42<00:44,  1.05trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 54%|                                      | 54/100 [00:43<00:47,  1.04s/trial, best loss: 1.7796852055007588]\u001b[A\n",
      " 55%|                                     | 55/100 [00:45<00:49,  1.10s/trial, best loss: 1.7796852055007588]\u001b[A\n",
      " 56%|                                     | 56/100 [00:45<00:37,  1.19trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 57%|                                    | 57/100 [00:45<00:30,  1.39trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 58%|                                   | 58/100 [00:45<00:22,  1.85trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 59%|                                  | 59/100 [00:46<00:27,  1.51trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 60%|                                 | 60/100 [00:48<00:35,  1.14trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 61%|                                | 61/100 [00:48<00:30,  1.27trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 62%|                                | 62/100 [00:49<00:25,  1.48trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 63%|                               | 63/100 [00:49<00:22,  1.62trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 64%|                              | 64/100 [00:49<00:18,  1.99trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 65%|                             | 65/100 [00:50<00:21,  1.66trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 66%|                            | 66/100 [00:51<00:24,  1.41trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 67%|                           | 67/100 [00:51<00:18,  1.76trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 68%|                           | 68/100 [00:52<00:18,  1.73trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 69%|                          | 69/100 [00:53<00:23,  1.32trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 70%|                         | 70/100 [00:54<00:24,  1.24trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 71%|                        | 71/100 [00:54<00:19,  1.52trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 72%|                       | 72/100 [00:55<00:19,  1.45trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 73%|                      | 73/100 [00:56<00:16,  1.64trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 74%|                     | 74/100 [00:56<00:18,  1.43trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 75%|                     | 75/100 [00:57<00:13,  1.83trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 76%|                    | 76/100 [00:57<00:13,  1.77trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 77%|                   | 77/100 [00:58<00:16,  1.37trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 78%|                  | 78/100 [00:59<00:14,  1.57trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 79%|                 | 79/100 [01:00<00:15,  1.35trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 80%|                | 80/100 [01:00<00:12,  1.62trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 81%|                | 81/100 [01:01<00:14,  1.29trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 82%|               | 82/100 [01:03<00:17,  1.01trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 83%|              | 83/100 [01:03<00:12,  1.38trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 84%|             | 84/100 [01:04<00:11,  1.43trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 85%|            | 85/100 [01:04<00:10,  1.49trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 86%|           | 86/100 [01:04<00:07,  1.97trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 87%|           | 87/100 [01:05<00:08,  1.46trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 88%|          | 88/100 [01:07<00:10,  1.19trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 89%|         | 89/100 [01:07<00:09,  1.18trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 90%|        | 90/100 [01:08<00:06,  1.49trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 91%|       | 91/100 [01:08<00:05,  1.73trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 92%|      | 92/100 [01:09<00:04,  1.79trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 93%|      | 93/100 [01:09<00:03,  1.94trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 94%|     | 94/100 [01:10<00:03,  1.63trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 95%|    | 95/100 [01:11<00:03,  1.31trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 96%|   | 96/100 [01:11<00:02,  1.55trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 97%|  | 97/100 [01:11<00:01,  1.99trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 98%| | 98/100 [01:12<00:01,  1.66trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      " 99%|| 99/100 [01:13<00:00,  1.50trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      "100%|| 100/100 [01:14<00:00,  1.34trial/s, best loss: 1.7796852055007588]\u001b[A\n",
      "Best hyperparameter set for random_forest is {'max_depth': 15, 'n_estimators': 260}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8ea363be83b4546875e54d0aa7f7f30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Doing PCA(151):   0%|          | 0/1 [00:00<?, ?images/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing random_forest model...\n",
      "\n",
      "  0%|                                                                                                               | 0/100 [00:00<?, ?trial/s, best loss=?]\u001b[A\n",
      "  1%|                                                                                     | 1/100 [00:01<02:23,  1.45s/trial, best loss: 1.834029419222194]\u001b[A\n",
      "  2%|                                                                                    | 2/100 [00:02<02:06,  1.29s/trial, best loss: 1.834029419222194]\u001b[A\n",
      "  3%|                                                                                   | 3/100 [00:03<01:34,  1.02trial/s, best loss: 1.834029419222194]\u001b[A\n",
      "  4%|                                                                                  | 4/100 [00:04<01:49,  1.14s/trial, best loss: 1.834029419222194]\u001b[A\n",
      "  5%|                                                                                 | 5/100 [00:05<01:23,  1.14trial/s, best loss: 1.834029419222194]\u001b[A\n",
      "  6%|                                                                                | 6/100 [00:06<01:36,  1.02s/trial, best loss: 1.834029419222194]\u001b[A\n",
      "  7%|                                                                                | 7/100 [00:07<01:27,  1.07trial/s, best loss: 1.834029419222194]\u001b[A\n",
      "  8%|                                                                               | 8/100 [00:08<01:40,  1.09s/trial, best loss: 1.834029419222194]\u001b[A\n",
      "  9%|                                                                              | 9/100 [00:09<01:32,  1.02s/trial, best loss: 1.834029419222194]\u001b[A\n",
      " 10%|                                                                            | 10/100 [00:09<01:16,  1.18trial/s, best loss: 1.834029419222194]\u001b[A\n",
      " 11%|                                                                           | 11/100 [00:11<01:26,  1.03trial/s, best loss: 1.834029419222194]\u001b[A\n",
      " 12%|                                                                          | 12/100 [00:11<01:21,  1.08trial/s, best loss: 1.834029419222194]\u001b[A\n",
      " 13%|                                                                          | 13/100 [00:12<01:02,  1.40trial/s, best loss: 1.834029419222194]\u001b[A\n",
      " 14%|                                                                         | 14/100 [00:13<01:17,  1.11trial/s, best loss: 1.834029419222194]\u001b[A\n",
      " 15%|                                                                        | 15/100 [00:14<01:10,  1.20trial/s, best loss: 1.834029419222194]\u001b[A\n",
      " 16%|                                                                       | 16/100 [00:15<01:15,  1.12trial/s, best loss: 1.834029419222194]\u001b[A\n",
      " 17%|                                                                      | 17/100 [00:15<00:55,  1.49trial/s, best loss: 1.834029419222194]\u001b[A\n",
      " 18%|                                                                     | 18/100 [00:16<01:09,  1.17trial/s, best loss: 1.834029419222194]\u001b[A\n",
      " 19%|                                                                    | 19/100 [00:16<00:51,  1.58trial/s, best loss: 1.834029419222194]\u001b[A\n",
      " 20%|                                                                   | 20/100 [00:18<01:15,  1.07trial/s, best loss: 1.8330613242237692]\u001b[A\n",
      " 21%|                                                                  | 21/100 [00:19<01:19,  1.00s/trial, best loss: 1.8330613242237692]\u001b[A\n",
      " 22%|                                                                 | 22/100 [00:20<01:25,  1.10s/trial, best loss: 1.8330613242237692]\u001b[A\n",
      " 23%|                                                                | 23/100 [00:22<01:35,  1.24s/trial, best loss: 1.8330613242237692]\u001b[A\n",
      " 24%|                                                               | 24/100 [00:23<01:19,  1.04s/trial, best loss: 1.8330613242237692]\u001b[A\n",
      " 25%|                                                               | 25/100 [00:23<01:13,  1.02trial/s, best loss: 1.8330613242237692]\u001b[A\n",
      " 26%|                                                              | 26/100 [00:23<00:53,  1.38trial/s, best loss: 1.8330613242237692]\u001b[A\n",
      " 27%|                                                             | 27/100 [00:24<00:49,  1.46trial/s, best loss: 1.8330613242237692]\u001b[A\n",
      " 28%|                                                            | 28/100 [00:25<01:00,  1.19trial/s, best loss: 1.8330613242237692]\u001b[A\n",
      " 29%|                                                           | 29/100 [00:27<01:09,  1.03trial/s, best loss: 1.8330613242237692]\u001b[A\n",
      " 30%|                                                          | 30/100 [00:28<01:20,  1.15s/trial, best loss: 1.8330613242237692]\u001b[A\n",
      " 31%|                                                          | 31/100 [00:30<01:26,  1.25s/trial, best loss: 1.8330613242237692]\u001b[A\n",
      " 32%|                                                         | 32/100 [00:30<01:09,  1.03s/trial, best loss: 1.8330613242237692]\u001b[A\n",
      " 33%|                                                        | 33/100 [00:32<01:18,  1.17s/trial, best loss: 1.8330613242237692]\u001b[A\n",
      " 34%|                                                       | 34/100 [00:33<01:20,  1.22s/trial, best loss: 1.8330613242237692]\u001b[A\n",
      " 35%|                                                      | 35/100 [00:34<01:15,  1.17s/trial, best loss: 1.8330613242237692]\u001b[A\n",
      " 36%|                                                     | 36/100 [00:35<01:12,  1.13s/trial, best loss: 1.8330613242237692]\u001b[A\n",
      " 37%|                                                     | 37/100 [00:36<01:03,  1.01s/trial, best loss: 1.8330613242237692]\u001b[A\n",
      " 38%|                                                    | 38/100 [00:36<00:54,  1.13trial/s, best loss: 1.8330613242237692]\u001b[A\n",
      " 39%|                                                   | 39/100 [00:37<00:42,  1.44trial/s, best loss: 1.8330613242237692]\u001b[A\n",
      " 40%|                                                  | 40/100 [00:37<00:41,  1.46trial/s, best loss: 1.8330613242237692]\u001b[A\n",
      " 41%|                                                 | 41/100 [00:38<00:43,  1.36trial/s, best loss: 1.8330613242237692]\u001b[A\n",
      " 42%|                                                | 42/100 [00:38<00:33,  1.75trial/s, best loss: 1.8330613242237692]\u001b[A\n",
      " 43%|                                                | 43/100 [00:39<00:37,  1.52trial/s, best loss: 1.8330613242237692]\u001b[A\n",
      " 44%|                                               | 44/100 [00:40<00:46,  1.21trial/s, best loss: 1.8330613242237692]\u001b[A\n",
      " 45%|                                              | 45/100 [00:41<00:37,  1.47trial/s, best loss: 1.8330613242237692]\u001b[A\n",
      " 46%|                                             | 46/100 [00:41<00:32,  1.66trial/s, best loss: 1.8330613242237692]\u001b[A\n",
      " 47%|                                            | 47/100 [00:43<00:45,  1.17trial/s, best loss: 1.8330613242237692]\u001b[A\n",
      " 48%|                                           | 48/100 [00:43<00:44,  1.16trial/s, best loss: 1.8330613242237692]\u001b[A\n",
      " 49%|                                          | 49/100 [00:44<00:33,  1.52trial/s, best loss: 1.8330613242237692]\u001b[A\n",
      " 50%|                                          | 50/100 [00:44<00:29,  1.69trial/s, best loss: 1.8330613242237692]\u001b[A\n",
      " 51%|                                         | 51/100 [00:46<00:41,  1.18trial/s, best loss: 1.8330613242237692]\u001b[A\n",
      " 52%|                                        | 52/100 [00:47<00:46,  1.04trial/s, best loss: 1.8330613242237692]\u001b[A\n",
      " 53%|                                       | 53/100 [00:48<00:48,  1.04s/trial, best loss: 1.8330613242237692]\u001b[A\n",
      " 54%|                                      | 54/100 [00:49<00:42,  1.09trial/s, best loss: 1.8330613242237692]\u001b[A\n",
      " 55%|                                     | 55/100 [00:49<00:33,  1.35trial/s, best loss: 1.8330613242237692]\u001b[A\n",
      " 56%|                                     | 56/100 [00:49<00:28,  1.55trial/s, best loss: 1.8330613242237692]\u001b[A\n",
      " 57%|                                    | 57/100 [00:50<00:33,  1.28trial/s, best loss: 1.8330613242237692]\u001b[A\n",
      " 58%|                                   | 58/100 [00:52<00:39,  1.06trial/s, best loss: 1.8330613242237692]\u001b[A\n",
      " 59%|                                  | 59/100 [00:52<00:30,  1.33trial/s, best loss: 1.8330613242237692]\u001b[A\n",
      " 60%|                                 | 60/100 [00:53<00:27,  1.43trial/s, best loss: 1.8330613242237692]\u001b[A\n",
      " 61%|                                | 61/100 [00:54<00:38,  1.01trial/s, best loss: 1.8330613242237692]\u001b[A\n",
      " 62%|                                | 62/100 [00:56<00:44,  1.18s/trial, best loss: 1.8330613242237692]\u001b[A\n",
      " 63%|                               | 63/100 [00:57<00:41,  1.12s/trial, best loss: 1.8330613242237692]\u001b[A\n",
      " 64%|                              | 64/100 [00:57<00:34,  1.06trial/s, best loss: 1.8330613242237692]\u001b[A\n",
      " 65%|                             | 65/100 [00:58<00:26,  1.31trial/s, best loss: 1.8330613242237692]\u001b[A\n",
      " 66%|                            | 66/100 [00:59<00:35,  1.03s/trial, best loss: 1.8330613242237692]\u001b[A\n",
      " 67%|                           | 67/100 [01:00<00:28,  1.16trial/s, best loss: 1.8330613242237692]\u001b[A\n",
      " 68%|                           | 68/100 [01:01<00:33,  1.06s/trial, best loss: 1.8330613242237692]\u001b[A\n",
      " 69%|                          | 69/100 [01:02<00:30,  1.02trial/s, best loss: 1.8330613242237692]\u001b[A\n",
      " 70%|                         | 70/100 [01:03<00:27,  1.08trial/s, best loss: 1.8330613242237692]\u001b[A\n",
      " 71%|                        | 71/100 [01:04<00:26,  1.10trial/s, best loss: 1.8330613242237692]\u001b[A\n",
      " 72%|                       | 72/100 [01:05<00:28,  1.01s/trial, best loss: 1.8330613242237692]\u001b[A\n",
      " 73%|                      | 73/100 [01:05<00:20,  1.29trial/s, best loss: 1.8330613242237692]\u001b[A\n",
      " 74%|                     | 74/100 [01:06<00:22,  1.17trial/s, best loss: 1.8330613242237692]\u001b[A\n",
      " 75%|                     | 75/100 [01:07<00:16,  1.51trial/s, best loss: 1.8330613242237692]\u001b[A\n",
      " 76%|                    | 76/100 [01:08<00:22,  1.08trial/s, best loss: 1.8330613242237692]\u001b[A\n",
      " 77%|                   | 77/100 [01:09<00:20,  1.12trial/s, best loss: 1.8330613242237692]\u001b[A\n",
      " 78%|                  | 78/100 [01:10<00:18,  1.20trial/s, best loss: 1.8330613242237692]\u001b[A\n",
      " 79%|                 | 79/100 [01:11<00:21,  1.01s/trial, best loss: 1.8330613242237692]\u001b[A\n",
      " 80%|                | 80/100 [01:11<00:16,  1.23trial/s, best loss: 1.8330613242237692]\u001b[A\n",
      " 81%|                | 81/100 [01:12<00:15,  1.25trial/s, best loss: 1.8330613242237692]\u001b[A\n",
      " 82%|               | 82/100 [01:14<00:18,  1.05s/trial, best loss: 1.8330613242237692]\u001b[A\n",
      " 83%|              | 83/100 [01:14<00:14,  1.16trial/s, best loss: 1.8330613242237692]\u001b[A\n",
      " 84%|             | 84/100 [01:15<00:13,  1.16trial/s, best loss: 1.8330613242237692]\u001b[A\n",
      " 85%|            | 85/100 [01:16<00:14,  1.03trial/s, best loss: 1.8330613242237692]\u001b[A\n",
      " 86%|           | 86/100 [01:17<00:12,  1.11trial/s, best loss: 1.8330613242237692]\u001b[A\n",
      " 87%|           | 87/100 [01:18<00:10,  1.19trial/s, best loss: 1.8330613242237692]\u001b[A\n",
      " 88%|          | 88/100 [01:18<00:09,  1.31trial/s, best loss: 1.8330613242237692]\u001b[A\n",
      " 89%|         | 89/100 [01:19<00:09,  1.22trial/s, best loss: 1.8330613242237692]\u001b[A\n",
      " 91%|       | 91/100 [01:21<00:06,  1.30trial/s, best loss: 1.8330613242237692]\u001b[A\n",
      " 92%|      | 92/100 [01:21<00:05,  1.38trial/s, best loss: 1.8330613242237692]\u001b[A\n",
      " 93%|      | 93/100 [01:22<00:04,  1.47trial/s, best loss: 1.8330613242237692]\u001b[A\n",
      " 94%|     | 94/100 [01:23<00:04,  1.28trial/s, best loss: 1.8330613242237692]\u001b[A\n",
      " 95%|    | 95/100 [01:24<00:04,  1.14trial/s, best loss: 1.8330613242237692]\u001b[A\n",
      " 96%|   | 96/100 [01:24<00:02,  1.49trial/s, best loss: 1.8330613242237692]\u001b[A\n",
      " 97%|  | 97/100 [01:26<00:02,  1.07trial/s, best loss: 1.8330613242237692]\u001b[A\n",
      " 98%| | 98/100 [01:26<00:01,  1.17trial/s, best loss: 1.8330613242237692]\u001b[A\n",
      " 99%|| 99/100 [01:28<00:00,  1.00trial/s, best loss: 1.8330613242237692]\u001b[A\n",
      "100%|| 100/100 [01:28<00:00,  1.13trial/s, best loss: 1.8330613242237692]\u001b[A\n",
      "Best hyperparameter set for random_forest is {'max_depth': 13, 'n_estimators': 297}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeb2ee74d95e41bf8ca41a158d188a20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Doing PCA(201):   0%|          | 0/1 [00:00<?, ?images/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing random_forest model...\n",
      "\n",
      "  0%|                                                                                                               | 0/100 [00:00<?, ?trial/s, best loss=?]\u001b[A\n",
      "  1%|                                                                                    | 1/100 [00:00<01:26,  1.15trial/s, best loss: 1.9693259753094032]\u001b[A\n",
      "  2%|                                                                                   | 2/100 [00:02<01:42,  1.04s/trial, best loss: 1.8760108608785397]\u001b[A\n",
      "  3%|                                                                                  | 3/100 [00:03<01:45,  1.09s/trial, best loss: 1.8759943023079295]\u001b[A\n",
      "  4%|                                                                                 | 4/100 [00:03<01:21,  1.18trial/s, best loss: 1.8759943023079295]\u001b[A\n",
      "  5%|                                                                                | 5/100 [00:04<01:34,  1.00trial/s, best loss: 1.8759943023079295]\u001b[A\n",
      "  7%|                                                                               | 7/100 [00:05<00:50,  1.82trial/s, best loss: 1.8759943023079295]\u001b[A\n",
      "  8%|                                                                              | 8/100 [00:05<00:56,  1.64trial/s, best loss: 1.8759943023079295]\u001b[A\n",
      "  9%|                                                                             | 9/100 [00:07<01:10,  1.28trial/s, best loss: 1.8759943023079295]\u001b[A\n",
      " 10%|                                                                           | 10/100 [00:07<00:59,  1.51trial/s, best loss: 1.8759943023079295]\u001b[A\n",
      " 11%|                                                                          | 11/100 [00:08<01:09,  1.28trial/s, best loss: 1.8759943023079295]\u001b[A\n",
      " 12%|                                                                          | 12/100 [00:09<01:19,  1.10trial/s, best loss: 1.8759943023079295]\u001b[A\n",
      " 13%|                                                                         | 13/100 [00:09<00:59,  1.46trial/s, best loss: 1.8759943023079295]\u001b[A\n",
      " 14%|                                                                        | 14/100 [00:11<01:21,  1.06trial/s, best loss: 1.8683310477813209]\u001b[A\n",
      " 15%|                                                                       | 15/100 [00:12<01:28,  1.04s/trial, best loss: 1.8683310477813209]\u001b[A\n",
      " 16%|                                                                      | 16/100 [00:13<01:31,  1.09s/trial, best loss: 1.8683310477813209]\u001b[A\n",
      " 17%|                                                                     | 17/100 [00:14<01:14,  1.12trial/s, best loss: 1.8683310477813209]\u001b[A\n",
      " 18%|                                                                     | 18/100 [00:14<01:00,  1.35trial/s, best loss: 1.8683310477813209]\u001b[A\n",
      " 19%|                                                                    | 19/100 [00:15<00:52,  1.56trial/s, best loss: 1.8683310477813209]\u001b[A\n",
      " 20%|                                                                   | 20/100 [00:16<00:57,  1.38trial/s, best loss: 1.8683310477813209]\u001b[A\n",
      " 21%|                                                                  | 21/100 [00:17<01:03,  1.24trial/s, best loss: 1.8683310477813209]\u001b[A\n",
      " 22%|                                                                 | 22/100 [00:18<01:06,  1.16trial/s, best loss: 1.8683310477813209]\u001b[A\n",
      " 23%|                                                                | 23/100 [00:19<01:27,  1.14s/trial, best loss: 1.8683310477813209]\u001b[A\n",
      " 24%|                                                               | 24/100 [00:20<01:09,  1.09trial/s, best loss: 1.8683310477813209]\u001b[A\n",
      " 25%|                                                               | 25/100 [00:21<01:21,  1.09s/trial, best loss: 1.8683310477813209]\u001b[A\n",
      " 26%|                                                              | 26/100 [00:23<01:26,  1.17s/trial, best loss: 1.8683310477813209]\u001b[A\n",
      " 27%|                                                             | 27/100 [00:24<01:26,  1.19s/trial, best loss: 1.8683310477813209]\u001b[A\n",
      " 28%|                                                            | 28/100 [00:24<01:03,  1.13trial/s, best loss: 1.8683310477813209]\u001b[A\n",
      " 29%|                                                           | 29/100 [00:24<00:50,  1.39trial/s, best loss: 1.8683310477813209]\u001b[A\n",
      " 30%|                                                          | 30/100 [00:25<00:47,  1.48trial/s, best loss: 1.8683310477813209]\u001b[A\n",
      " 31%|                                                          | 31/100 [00:26<00:57,  1.21trial/s, best loss: 1.8683310477813209]\u001b[A\n",
      " 32%|                                                         | 32/100 [00:27<00:54,  1.24trial/s, best loss: 1.8683310477813209]\u001b[A\n",
      " 33%|                                                        | 33/100 [00:28<01:09,  1.04s/trial, best loss: 1.8683310477813209]\u001b[A\n",
      " 34%|                                                       | 34/100 [00:29<01:01,  1.07trial/s, best loss: 1.8683310477813209]\u001b[A\n",
      " 35%|                                                      | 35/100 [00:31<01:12,  1.12s/trial, best loss: 1.8683310477813209]\u001b[A\n",
      " 36%|                                                     | 36/100 [00:32<01:10,  1.10s/trial, best loss: 1.8683310477813209]\u001b[A\n",
      " 37%|                                                     | 37/100 [00:33<01:15,  1.20s/trial, best loss: 1.8683310477813209]\u001b[A\n",
      " 38%|                                                    | 38/100 [00:34<01:12,  1.18s/trial, best loss: 1.8683310477813209]\u001b[A\n",
      " 39%|                                                   | 39/100 [00:35<00:54,  1.12trial/s, best loss: 1.8683310477813209]\u001b[A\n",
      " 40%|                                                  | 40/100 [00:35<00:52,  1.14trial/s, best loss: 1.8683310477813209]\u001b[A\n",
      " 41%|                                                 | 41/100 [00:36<00:40,  1.44trial/s, best loss: 1.8683310477813209]\u001b[A\n",
      " 42%|                                                | 42/100 [00:36<00:30,  1.88trial/s, best loss: 1.8683310477813209]\u001b[A\n",
      " 43%|                                                | 43/100 [00:37<00:43,  1.30trial/s, best loss: 1.8683310477813209]\u001b[A\n",
      " 44%|                                               | 44/100 [00:37<00:33,  1.68trial/s, best loss: 1.8683310477813209]\u001b[A\n",
      " 45%|                                              | 45/100 [00:38<00:27,  2.00trial/s, best loss: 1.8683310477813209]\u001b[A\n",
      " 46%|                                             | 46/100 [00:39<00:45,  1.20trial/s, best loss: 1.8683310477813209]\u001b[A\n",
      " 47%|                                            | 47/100 [00:39<00:33,  1.59trial/s, best loss: 1.8683310477813209]\u001b[A\n",
      " 48%|                                           | 48/100 [00:40<00:32,  1.59trial/s, best loss: 1.8683310477813209]\u001b[A\n",
      " 49%|                                          | 49/100 [00:42<00:45,  1.11trial/s, best loss: 1.8683310477813209]\u001b[A\n",
      " 50%|                                          | 50/100 [00:42<00:35,  1.39trial/s, best loss: 1.8683310477813209]\u001b[A\n",
      " 51%|                                         | 51/100 [00:43<00:40,  1.20trial/s, best loss: 1.8683310477813209]\u001b[A\n",
      " 52%|                                        | 52/100 [00:44<00:40,  1.19trial/s, best loss: 1.8683310477813209]\u001b[A\n",
      " 53%|                                       | 53/100 [00:45<00:44,  1.05trial/s, best loss: 1.8683310477813209]\u001b[A\n",
      " 54%|                                      | 54/100 [00:45<00:37,  1.23trial/s, best loss: 1.8683310477813209]\u001b[A\n",
      " 55%|                                     | 55/100 [00:46<00:35,  1.27trial/s, best loss: 1.8683310477813209]\u001b[A\n",
      " 56%|                                     | 56/100 [00:47<00:38,  1.14trial/s, best loss: 1.8683310477813209]\u001b[A\n",
      " 57%|                                    | 57/100 [00:49<00:45,  1.06s/trial, best loss: 1.8683310477813209]\u001b[A\n",
      " 58%|                                   | 58/100 [00:50<00:44,  1.05s/trial, best loss: 1.8683310477813209]\u001b[A\n",
      " 59%|                                  | 59/100 [00:51<00:41,  1.02s/trial, best loss: 1.8683310477813209]\u001b[A\n",
      " 60%|                                 | 60/100 [00:51<00:37,  1.08trial/s, best loss: 1.8683310477813209]\u001b[A\n",
      " 61%|                                | 61/100 [00:53<00:43,  1.12s/trial, best loss: 1.8683310477813209]\u001b[A\n",
      " 62%|                                | 62/100 [00:53<00:34,  1.11trial/s, best loss: 1.8683310477813209]\u001b[A\n",
      " 63%|                               | 63/100 [00:55<00:35,  1.05trial/s, best loss: 1.8683310477813209]\u001b[A\n",
      " 64%|                              | 64/100 [00:56<00:35,  1.00trial/s, best loss: 1.8683310477813209]\u001b[A\n",
      " 65%|                             | 65/100 [00:56<00:32,  1.07trial/s, best loss: 1.8683310477813209]\u001b[A\n",
      " 66%|                            | 66/100 [00:57<00:27,  1.26trial/s, best loss: 1.8683310477813209]\u001b[A\n",
      " 67%|                           | 67/100 [00:59<00:36,  1.09s/trial, best loss: 1.8683310477813209]\u001b[A\n",
      " 68%|                           | 68/100 [00:59<00:31,  1.00trial/s, best loss: 1.8683310477813209]\u001b[A\n",
      " 69%|                          | 69/100 [01:00<00:23,  1.31trial/s, best loss: 1.8683310477813209]\u001b[A\n",
      " 70%|                         | 70/100 [01:00<00:21,  1.37trial/s, best loss: 1.8683310477813209]\u001b[A\n",
      " 71%|                        | 71/100 [01:01<00:25,  1.15trial/s, best loss: 1.8683310477813209]\u001b[A\n",
      " 72%|                       | 72/100 [01:02<00:20,  1.40trial/s, best loss: 1.8683310477813209]\u001b[A\n",
      " 73%|                      | 73/100 [01:03<00:22,  1.20trial/s, best loss: 1.8683310477813209]\u001b[A\n",
      " 74%|                     | 74/100 [01:04<00:21,  1.24trial/s, best loss: 1.8683310477813209]\u001b[A\n",
      " 75%|                     | 75/100 [01:05<00:25,  1.03s/trial, best loss: 1.8683310477813209]\u001b[A\n",
      " 76%|                    | 76/100 [01:06<00:21,  1.12trial/s, best loss: 1.8683310477813209]\u001b[A\n",
      " 77%|                   | 77/100 [01:07<00:24,  1.06s/trial, best loss: 1.8683310477813209]\u001b[A\n",
      " 78%|                  | 78/100 [01:08<00:23,  1.06s/trial, best loss: 1.8683310477813209]\u001b[A\n",
      " 79%|                 | 79/100 [01:09<00:17,  1.23trial/s, best loss: 1.8683310477813209]\u001b[A\n",
      " 80%|                | 80/100 [01:10<00:17,  1.12trial/s, best loss: 1.8683310477813209]\u001b[A\n",
      " 81%|                | 81/100 [01:10<00:16,  1.17trial/s, best loss: 1.8683310477813209]\u001b[A\n",
      " 82%|               | 82/100 [01:12<00:20,  1.12s/trial, best loss: 1.8683310477813209]\u001b[A\n",
      " 83%|              | 83/100 [01:13<00:18,  1.09s/trial, best loss: 1.8683310477813209]\u001b[A\n",
      " 84%|             | 84/100 [01:14<00:17,  1.10s/trial, best loss: 1.8683310477813209]\u001b[A\n",
      " 85%|            | 85/100 [01:16<00:18,  1.25s/trial, best loss: 1.8683310477813209]\u001b[A\n",
      " 86%|           | 86/100 [01:17<00:17,  1.22s/trial, best loss: 1.8683310477813209]\u001b[A\n",
      " 87%|           | 87/100 [01:18<00:13,  1.03s/trial, best loss: 1.8683310477813209]\u001b[A\n",
      " 88%|          | 88/100 [01:18<00:11,  1.06trial/s, best loss: 1.8683310477813209]\u001b[A\n",
      " 89%|         | 89/100 [01:19<00:07,  1.41trial/s, best loss: 1.8683310477813209]\u001b[A\n",
      " 90%|        | 90/100 [01:20<00:08,  1.18trial/s, best loss: 1.8683310477813209]\u001b[A\n",
      " 91%|       | 91/100 [01:21<00:08,  1.05trial/s, best loss: 1.8683310477813209]\u001b[A\n",
      " 92%|      | 92/100 [01:22<00:07,  1.08trial/s, best loss: 1.8683310477813209]\u001b[A\n",
      " 93%|      | 93/100 [01:22<00:05,  1.20trial/s, best loss: 1.8683310477813209]\u001b[A\n",
      " 94%|     | 94/100 [01:23<00:04,  1.39trial/s, best loss: 1.8683310477813209]\u001b[A\n",
      " 95%|    | 95/100 [01:24<00:03,  1.41trial/s, best loss: 1.8683310477813209]\u001b[A\n",
      " 96%|   | 96/100 [01:24<00:02,  1.40trial/s, best loss: 1.8683310477813209]\u001b[A\n",
      " 97%|  | 97/100 [01:25<00:01,  1.57trial/s, best loss: 1.8683310477813209]\u001b[A\n",
      " 98%| | 98/100 [01:26<00:01,  1.25trial/s, best loss: 1.8683310477813209]\u001b[A\n",
      "100%|| 100/100 [01:26<00:00,  1.15trial/s, best loss: 1.8683310477813209]\u001b[A\n",
      "Best hyperparameter set for random_forest is {'max_depth': 13, 'n_estimators': 268}\n",
      "\n",
      "\n",
      "Optimizing random_forest model...\n",
      "\n",
      "  0%|                                                                                                               | 0/100 [00:00<?, ?trial/s, best loss=?]\u001b[A\n",
      "  1%|                                                                                    | 1/100 [00:10<16:35, 10.05s/trial, best loss: 1.8354510699635547]\u001b[A\n",
      "  2%|                                                                                   | 2/100 [00:17<13:34,  8.31s/trial, best loss: 1.8300835223588319]\u001b[A\n",
      "  3%|                                                                                  | 3/100 [00:22<11:02,  6.83s/trial, best loss: 1.8300835223588319]\u001b[A\n",
      "  4%|                                                                                 | 4/100 [00:28<10:43,  6.70s/trial, best loss: 1.8300835223588319]\u001b[A\n",
      "  5%|                                                                                | 5/100 [00:33<09:47,  6.19s/trial, best loss: 1.8300835223588319]\u001b[A\n",
      "  6%|                                                                                | 6/100 [00:38<08:48,  5.62s/trial, best loss: 1.8300835223588319]\u001b[A\n",
      "  7%|                                                                               | 7/100 [00:47<10:37,  6.85s/trial, best loss: 1.8300835223588319]\u001b[A\n",
      "  8%|                                                                              | 8/100 [00:51<08:50,  5.76s/trial, best loss: 1.8300835223588319]\u001b[A\n",
      "  9%|                                                                              | 9/100 [00:59<09:51,  6.50s/trial, best loss: 1.804592682235608]\u001b[A\n",
      " 10%|                                                                            | 10/100 [01:04<08:57,  5.97s/trial, best loss: 1.804592682235608]\u001b[A\n",
      " 11%|                                                                           | 11/100 [01:07<07:42,  5.20s/trial, best loss: 1.804592682235608]\u001b[A\n",
      " 12%|                                                                          | 12/100 [01:12<07:27,  5.08s/trial, best loss: 1.804592682235608]\u001b[A\n",
      " 13%|                                                                          | 13/100 [01:20<08:33,  5.90s/trial, best loss: 1.804592682235608]\u001b[A\n",
      " 14%|                                                                         | 14/100 [01:21<06:38,  4.63s/trial, best loss: 1.804592682235608]\u001b[A\n",
      " 15%|                                                                        | 15/100 [01:27<06:51,  4.85s/trial, best loss: 1.804592682235608]\u001b[A\n",
      " 16%|                                                                       | 16/100 [01:31<06:28,  4.62s/trial, best loss: 1.804592682235608]\u001b[A\n",
      " 17%|                                                                      | 17/100 [01:35<06:10,  4.46s/trial, best loss: 1.804592682235608]\u001b[A\n",
      " 18%|                                                                     | 18/100 [01:42<07:00,  5.12s/trial, best loss: 1.804592682235608]\u001b[A\n",
      " 19%|                                                                    | 19/100 [01:51<08:43,  6.47s/trial, best loss: 1.7920359844938514]\u001b[A\n",
      " 20%|                                                                   | 20/100 [01:58<08:49,  6.61s/trial, best loss: 1.7920359844938514]\u001b[A\n",
      " 21%|                                                                  | 21/100 [02:07<09:24,  7.14s/trial, best loss: 1.7920359844938514]\u001b[A\n",
      " 22%|                                                                 | 22/100 [02:10<07:42,  5.92s/trial, best loss: 1.7920359844938514]\u001b[A\n",
      " 23%|                                                                | 23/100 [02:18<08:28,  6.60s/trial, best loss: 1.7920359844938514]\u001b[A\n",
      " 24%|                                                               | 24/100 [02:27<09:16,  7.32s/trial, best loss: 1.7920359844938514]\u001b[A\n",
      " 25%|                                                               | 25/100 [02:32<08:12,  6.57s/trial, best loss: 1.7920359844938514]\u001b[A\n",
      " 26%|                                                              | 26/100 [02:37<07:36,  6.16s/trial, best loss: 1.7920359844938514]\u001b[A\n",
      " 27%|                                                             | 27/100 [02:41<06:48,  5.60s/trial, best loss: 1.7920359844938514]\u001b[A\n",
      " 28%|                                                            | 28/100 [02:47<06:47,  5.66s/trial, best loss: 1.7920359844938514]\u001b[A\n",
      " 29%|                                                           | 29/100 [02:55<07:33,  6.39s/trial, best loss: 1.7920359844938514]\u001b[A\n",
      " 30%|                                                          | 30/100 [03:02<07:34,  6.49s/trial, best loss: 1.7920359844938514]\u001b[A\n",
      " 31%|                                                          | 31/100 [03:08<07:20,  6.38s/trial, best loss: 1.7920359844938514]\u001b[A\n",
      " 32%|                                                         | 32/100 [03:18<08:21,  7.38s/trial, best loss: 1.7901857360225968]\u001b[A\n",
      " 33%|                                                        | 33/100 [03:28<09:10,  8.22s/trial, best loss: 1.7901857360225968]\u001b[A\n",
      " 34%|                                                       | 34/100 [03:34<08:19,  7.57s/trial, best loss: 1.7901857360225968]\u001b[A\n",
      " 35%|                                                      | 35/100 [03:40<07:49,  7.22s/trial, best loss: 1.7901857360225968]\u001b[A\n",
      " 36%|                                                     | 36/100 [03:43<06:06,  5.73s/trial, best loss: 1.7901857360225968]\u001b[A\n",
      " 37%|                                                     | 37/100 [03:46<05:18,  5.05s/trial, best loss: 1.7901857360225968]\u001b[A\n",
      " 38%|                                                    | 38/100 [03:50<04:59,  4.83s/trial, best loss: 1.7901857360225968]\u001b[A\n",
      " 39%|                                                   | 39/100 [03:59<06:12,  6.11s/trial, best loss: 1.7901857360225968]\u001b[A\n",
      " 40%|                                                  | 40/100 [04:03<05:16,  5.28s/trial, best loss: 1.7901857360225968]\u001b[A\n",
      " 41%|                                                 | 41/100 [04:12<06:21,  6.46s/trial, best loss: 1.7901857360225968]\u001b[A\n",
      " 42%|                                                | 42/100 [04:18<06:13,  6.45s/trial, best loss: 1.7901857360225968]\u001b[A\n",
      " 43%|                                                | 43/100 [04:22<05:23,  5.68s/trial, best loss: 1.7901857360225968]\u001b[A\n",
      " 44%|                                               | 44/100 [04:28<05:22,  5.75s/trial, best loss: 1.7901857360225968]\u001b[A\n",
      " 45%|                                              | 45/100 [04:31<04:23,  4.79s/trial, best loss: 1.7901857360225968]\u001b[A\n",
      " 46%|                                             | 46/100 [04:34<03:54,  4.35s/trial, best loss: 1.7901857360225968]\u001b[A\n",
      " 47%|                                            | 47/100 [04:37<03:35,  4.07s/trial, best loss: 1.7901857360225968]\u001b[A\n",
      " 48%|                                           | 48/100 [04:43<03:51,  4.44s/trial, best loss: 1.7901857360225968]\u001b[A\n",
      " 49%|                                          | 49/100 [04:45<03:15,  3.84s/trial, best loss: 1.7901857360225968]\u001b[A\n",
      " 50%|                                          | 50/100 [04:49<03:13,  3.86s/trial, best loss: 1.7901857360225968]\u001b[A\n",
      " 51%|                                         | 51/100 [04:52<02:56,  3.60s/trial, best loss: 1.7901857360225968]\u001b[A\n",
      " 52%|                                        | 52/100 [04:59<03:45,  4.69s/trial, best loss: 1.7901857360225968]\u001b[A\n",
      " 53%|                                       | 53/100 [05:01<02:54,  3.71s/trial, best loss: 1.7901857360225968]\u001b[A\n",
      " 54%|                                      | 54/100 [05:05<03:00,  3.92s/trial, best loss: 1.7901857360225968]\u001b[A\n",
      " 55%|                                     | 55/100 [05:12<03:30,  4.68s/trial, best loss: 1.7901857360225968]\u001b[A\n",
      " 56%|                                     | 56/100 [05:20<04:17,  5.84s/trial, best loss: 1.7901857360225968]\u001b[A\n",
      " 57%|                                    | 57/100 [05:26<04:08,  5.78s/trial, best loss: 1.7901857360225968]\u001b[A\n",
      " 58%|                                   | 58/100 [05:32<04:10,  5.97s/trial, best loss: 1.7901857360225968]\u001b[A\n",
      " 59%|                                  | 59/100 [05:37<03:48,  5.56s/trial, best loss: 1.7901857360225968]\u001b[A\n",
      " 60%|                                 | 60/100 [05:44<03:59,  5.98s/trial, best loss: 1.7901857360225968]\u001b[A\n",
      " 61%|                                | 61/100 [05:51<04:12,  6.47s/trial, best loss: 1.7901857360225968]\u001b[A\n",
      " 62%|                                | 62/100 [06:00<04:32,  7.18s/trial, best loss: 1.7901857360225968]\u001b[A\n",
      " 63%|                               | 63/100 [06:05<04:01,  6.54s/trial, best loss: 1.7901857360225968]\u001b[A\n",
      " 64%|                              | 64/100 [06:07<03:07,  5.20s/trial, best loss: 1.7901857360225968]\u001b[A\n",
      " 65%|                             | 65/100 [06:09<02:29,  4.27s/trial, best loss: 1.7901857360225968]\u001b[A\n",
      " 66%|                            | 66/100 [06:15<02:39,  4.70s/trial, best loss: 1.7901857360225968]\u001b[A\n",
      " 67%|                           | 67/100 [06:23<03:01,  5.51s/trial, best loss: 1.7901857360225968]\u001b[A\n",
      " 68%|                           | 68/100 [06:31<03:23,  6.35s/trial, best loss: 1.7901857360225968]\u001b[A\n",
      " 69%|                          | 69/100 [06:40<03:44,  7.26s/trial, best loss: 1.7901857360225968]\u001b[A\n",
      " 70%|                         | 70/100 [06:50<03:57,  7.93s/trial, best loss: 1.7900720332531228]\u001b[A\n",
      " 71%|                        | 71/100 [07:01<04:18,  8.92s/trial, best loss: 1.7892585670559853]\u001b[A\n",
      " 72%|                       | 72/100 [07:08<03:54,  8.38s/trial, best loss: 1.7892585670559853]\u001b[A\n",
      " 73%|                      | 73/100 [07:19<04:06,  9.15s/trial, best loss: 1.7892585670559853]\u001b[A\n",
      " 74%|                     | 74/100 [07:30<04:13,  9.76s/trial, best loss: 1.7892585670559853]\u001b[A\n",
      " 75%|                     | 75/100 [07:41<04:14, 10.19s/trial, best loss: 1.7892585670559853]\u001b[A\n",
      " 76%|                    | 76/100 [07:47<03:32,  8.87s/trial, best loss: 1.7892585670559853]\u001b[A\n",
      " 77%|                   | 77/100 [07:50<02:43,  7.13s/trial, best loss: 1.7892585670559853]\u001b[A\n",
      " 78%|                  | 78/100 [08:00<02:53,  7.87s/trial, best loss: 1.7892585670559853]\u001b[A\n",
      " 79%|                 | 79/100 [08:05<02:25,  6.92s/trial, best loss: 1.7892585670559853]\u001b[A\n",
      " 80%|                | 80/100 [08:10<02:09,  6.48s/trial, best loss: 1.7892585670559853]\u001b[A\n",
      " 81%|                | 81/100 [08:11<01:33,  4.93s/trial, best loss: 1.7892585670559853]\u001b[A\n",
      " 82%|               | 82/100 [08:13<01:11,  3.95s/trial, best loss: 1.7892585670559853]\u001b[A\n",
      " 83%|              | 83/100 [08:18<01:12,  4.26s/trial, best loss: 1.7892585670559853]\u001b[A\n",
      " 84%|             | 84/100 [08:21<00:59,  3.75s/trial, best loss: 1.7892585670559853]\u001b[A\n",
      " 85%|            | 85/100 [08:28<01:11,  4.77s/trial, best loss: 1.7892585670559853]\u001b[A\n",
      " 86%|           | 86/100 [08:38<01:31,  6.53s/trial, best loss: 1.7892585670559853]\u001b[A\n",
      " 87%|           | 87/100 [08:46<01:28,  6.84s/trial, best loss: 1.7892585670559853]\u001b[A\n",
      " 88%|          | 88/100 [08:55<01:30,  7.57s/trial, best loss: 1.7892585670559853]\u001b[A\n",
      " 89%|         | 89/100 [08:57<01:05,  5.95s/trial, best loss: 1.7892585670559853]\u001b[A\n",
      " 90%|        | 90/100 [09:00<00:49,  4.96s/trial, best loss: 1.7892585670559853]\u001b[A\n",
      " 91%|       | 91/100 [09:11<01:00,  6.68s/trial, best loss: 1.7892585670559853]\u001b[A\n",
      " 92%|      | 92/100 [09:21<01:02,  7.79s/trial, best loss: 1.7892585670559853]\u001b[A\n",
      " 93%|      | 93/100 [09:25<00:46,  6.67s/trial, best loss: 1.7892585670559853]\u001b[A\n",
      " 94%|     | 94/100 [09:31<00:38,  6.47s/trial, best loss: 1.7892585670559853]\u001b[A\n",
      " 95%|    | 95/100 [09:41<00:37,  7.54s/trial, best loss: 1.7892585670559853]\u001b[A\n",
      " 96%|   | 96/100 [09:51<00:32,  8.14s/trial, best loss: 1.7892585670559853]\u001b[A\n",
      " 97%|  | 97/100 [09:56<00:21,  7.18s/trial, best loss: 1.7892585670559853]\u001b[A\n",
      " 98%| | 98/100 [10:03<00:14,  7.14s/trial, best loss: 1.7892585670559853]\u001b[A\n",
      " 99%|| 99/100 [10:08<00:06,  6.71s/trial, best loss: 1.7892585670559853]\u001b[A\n",
      "100%|| 100/100 [10:16<00:00,  6.16s/trial, best loss: 1.7892585670559853]\u001b[A\n",
      "Best hyperparameter set for random_forest is {'max_depth': 18, 'n_estimators': 292}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def train_and_check(features, n_components, name, y, train_idx, val_idx):\n",
    "    pbar = tqdm(desc=name, total=len(n_components) + 1, position=0, leave=True)\n",
    "    acc = []\n",
    "    for n in n_components:\n",
    "        pbar.set_description(f'{name}: Computing PCA({n})')\n",
    "        _, X = feature_extractor.get_PCA([features], n_components=n+1)\n",
    "        acc.append(train_classifier(X[0], y, train_idx, val_idx))\n",
    "        pbar.update(1)\n",
    "    pbar.set_description(f'{name}: Training classifier')\n",
    "    acc.append(train_classifier(features, y, train_idx, val_idx))\n",
    "    pbar.update(1)\n",
    "    pbar.close()\n",
    "    return acc\n",
    "\n",
    "# get accuracy with different features\n",
    "n_components = [50, 100, 150, 200]\n",
    "# print('Pixel Feature Accuracy')\n",
    "# pixel_acc = train_and_check(pixel_features, n_components, 'Pixel', y, train_idx, val_idx)\n",
    "print('Pose Feature Accuracy')\n",
    "pose_acc = train_and_check(pose_features, n_components, 'Pose', y, train_idx, val_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6a6a7133-d2b5-425e-a26a-796e539cc38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Feature Accuracy\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12525f2083d64119b064c3a1ac2d1d5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CNN:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "511f671950d748e48216bc710c19fd18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Doing PCA(51):   0%|          | 0/1 [00:00<?, ?images/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing random_forest model...\n",
      "\n",
      "  0%|                                                                                                               | 0/100 [00:00<?, ?trial/s, best loss=?]\u001b[A\n",
      "  1%|                                                                                    | 1/100 [00:00<00:58,  1.69trial/s, best loss: 2.0927245349060426]\u001b[A\n",
      "  2%|                                                                                   | 2/100 [00:01<00:54,  1.79trial/s, best loss: 1.7501448584941766]\u001b[A\n",
      "  3%|                                                                                  | 3/100 [00:01<00:44,  2.20trial/s, best loss: 1.7501448584941766]\u001b[A\n",
      "  4%|                                                                                 | 4/100 [00:02<00:59,  1.62trial/s, best loss: 1.7501448584941766]\u001b[A\n",
      "  5%|                                                                                | 5/100 [00:02<00:47,  2.00trial/s, best loss: 1.7501448584941766]\u001b[A\n",
      "  6%|                                                                                | 6/100 [00:03<00:49,  1.91trial/s, best loss: 1.7501448584941766]\u001b[A\n",
      "  7%|                                                                               | 7/100 [00:03<00:53,  1.73trial/s, best loss: 1.7501448584941766]\u001b[A\n",
      "  8%|                                                                              | 8/100 [00:04<00:52,  1.75trial/s, best loss: 1.7501448584941766]\u001b[A\n",
      "  9%|                                                                             | 9/100 [00:04<00:43,  2.07trial/s, best loss: 1.7501448584941766]\u001b[A\n",
      " 10%|                                                                           | 10/100 [00:04<00:35,  2.53trial/s, best loss: 1.7501448584941766]\u001b[A\n",
      " 11%|                                                                          | 11/100 [00:05<00:52,  1.69trial/s, best loss: 1.7462613768621917]\u001b[A\n",
      " 12%|                                                                          | 12/100 [00:06<00:50,  1.74trial/s, best loss: 1.7462613768621917]\u001b[A\n",
      " 13%|                                                                          | 13/100 [00:07<00:49,  1.77trial/s, best loss: 1.744729085154825]\u001b[A\n",
      " 14%|                                                                         | 14/100 [00:07<00:52,  1.65trial/s, best loss: 1.744729085154825]\u001b[A\n",
      " 15%|                                                                        | 15/100 [00:08<00:59,  1.44trial/s, best loss: 1.744729085154825]\u001b[A\n",
      " 17%|                                                                      | 17/100 [00:09<00:43,  1.89trial/s, best loss: 1.744729085154825]\u001b[A\n",
      " 18%|                                                                     | 18/100 [00:09<00:40,  2.03trial/s, best loss: 1.744729085154825]\u001b[A\n",
      " 19%|                                                                    | 19/100 [00:10<00:37,  2.14trial/s, best loss: 1.744729085154825]\u001b[A\n",
      " 20%|                                                                    | 20/100 [00:10<00:43,  1.84trial/s, best loss: 1.744729085154825]\u001b[A\n",
      " 21%|                                                                   | 21/100 [00:11<00:39,  2.00trial/s, best loss: 1.744729085154825]\u001b[A\n",
      " 22%|                                                                  | 22/100 [00:11<00:42,  1.85trial/s, best loss: 1.744729085154825]\u001b[A\n",
      " 23%|                                                                 | 23/100 [00:12<00:35,  2.19trial/s, best loss: 1.744729085154825]\u001b[A\n",
      " 24%|                                                                | 24/100 [00:12<00:33,  2.26trial/s, best loss: 1.744729085154825]\u001b[A\n",
      " 25%|                                                               | 25/100 [00:13<00:35,  2.11trial/s, best loss: 1.744729085154825]\u001b[A\n",
      " 26%|                                                               | 26/100 [00:13<00:33,  2.18trial/s, best loss: 1.744729085154825]\u001b[A\n",
      " 27%|                                                              | 27/100 [00:14<00:45,  1.61trial/s, best loss: 1.744729085154825]\u001b[A\n",
      " 28%|                                                             | 28/100 [00:15<00:48,  1.47trial/s, best loss: 1.744729085154825]\u001b[A\n",
      " 29%|                                                            | 29/100 [00:16<00:49,  1.43trial/s, best loss: 1.744729085154825]\u001b[A\n",
      " 30%|                                                          | 30/100 [00:17<00:59,  1.17trial/s, best loss: 1.7443426808695246]\u001b[A\n",
      " 31%|                                                          | 31/100 [00:17<00:49,  1.41trial/s, best loss: 1.7443426808695246]\u001b[A\n",
      " 32%|                                                         | 32/100 [00:18<00:50,  1.35trial/s, best loss: 1.7443426808695246]\u001b[A\n",
      " 33%|                                                        | 33/100 [00:19<00:54,  1.23trial/s, best loss: 1.7443426808695246]\u001b[A\n",
      " 34%|                                                       | 34/100 [00:19<00:41,  1.61trial/s, best loss: 1.7443426808695246]\u001b[A\n",
      " 35%|                                                      | 35/100 [00:20<00:43,  1.51trial/s, best loss: 1.7430359587172994]\u001b[A\n",
      " 36%|                                                     | 36/100 [00:21<00:42,  1.50trial/s, best loss: 1.7430359587172994]\u001b[A\n",
      " 37%|                                                     | 37/100 [00:21<00:44,  1.41trial/s, best loss: 1.7430359587172994]\u001b[A\n",
      " 38%|                                                    | 38/100 [00:22<00:43,  1.44trial/s, best loss: 1.7430359587172994]\u001b[A\n",
      " 39%|                                                   | 39/100 [00:23<00:41,  1.48trial/s, best loss: 1.7430359587172994]\u001b[A\n",
      " 40%|                                                  | 40/100 [00:24<00:49,  1.22trial/s, best loss: 1.7430359587172994]\u001b[A\n",
      " 41%|                                                 | 41/100 [00:24<00:40,  1.46trial/s, best loss: 1.7430359587172994]\u001b[A\n",
      " 42%|                                                | 42/100 [00:25<00:39,  1.46trial/s, best loss: 1.7430359587172994]\u001b[A\n",
      " 43%|                                                | 43/100 [00:26<00:42,  1.33trial/s, best loss: 1.7430359587172994]\u001b[A\n",
      " 44%|                                               | 44/100 [00:27<00:48,  1.16trial/s, best loss: 1.7430359587172994]\u001b[A\n",
      " 45%|                                              | 45/100 [00:28<00:52,  1.05trial/s, best loss: 1.7385034265841655]\u001b[A\n",
      " 47%|                                            | 47/100 [00:29<00:39,  1.33trial/s, best loss: 1.7385034265841655]\u001b[A\n",
      " 48%|                                           | 48/100 [00:29<00:32,  1.61trial/s, best loss: 1.7385034265841655]\u001b[A\n",
      " 49%|                                          | 49/100 [00:30<00:32,  1.55trial/s, best loss: 1.7385034265841655]\u001b[A\n",
      " 50%|                                          | 50/100 [00:31<00:35,  1.41trial/s, best loss: 1.7385034265841655]\u001b[A\n",
      " 51%|                                         | 51/100 [00:32<00:33,  1.46trial/s, best loss: 1.7385034265841655]\u001b[A\n",
      " 53%|                                       | 53/100 [00:33<00:29,  1.57trial/s, best loss: 1.7385034265841655]\u001b[A\n",
      " 54%|                                      | 54/100 [00:34<00:34,  1.33trial/s, best loss: 1.7385034265841655]\u001b[A\n",
      " 55%|                                     | 55/100 [00:35<00:34,  1.29trial/s, best loss: 1.7385034265841655]\u001b[A\n",
      " 56%|                                     | 56/100 [00:35<00:27,  1.58trial/s, best loss: 1.7385034265841655]\u001b[A\n",
      " 57%|                                    | 57/100 [00:36<00:32,  1.33trial/s, best loss: 1.7385034265841655]\u001b[A\n",
      " 59%|                                  | 59/100 [00:36<00:21,  1.95trial/s, best loss: 1.7385034265841655]\u001b[A\n",
      " 60%|                                 | 60/100 [00:37<00:24,  1.64trial/s, best loss: 1.7385034265841655]\u001b[A\n",
      " 61%|                                | 61/100 [00:38<00:27,  1.43trial/s, best loss: 1.7385034265841655]\u001b[A\n",
      " 62%|                                | 62/100 [00:39<00:23,  1.61trial/s, best loss: 1.7385034265841655]\u001b[A\n",
      " 63%|                               | 63/100 [00:39<00:18,  2.04trial/s, best loss: 1.7385034265841655]\u001b[A\n",
      " 64%|                              | 64/100 [00:39<00:16,  2.19trial/s, best loss: 1.7385034265841655]\u001b[A\n",
      " 65%|                             | 65/100 [00:40<00:20,  1.68trial/s, best loss: 1.7385034265841655]\u001b[A\n",
      " 66%|                            | 66/100 [00:41<00:23,  1.47trial/s, best loss: 1.7385034265841655]\u001b[A\n",
      " 67%|                           | 67/100 [00:41<00:18,  1.81trial/s, best loss: 1.7385034265841655]\u001b[A\n",
      " 68%|                           | 68/100 [00:41<00:13,  2.31trial/s, best loss: 1.7385034265841655]\u001b[A\n",
      " 70%|                         | 70/100 [00:42<00:11,  2.69trial/s, best loss: 1.7385034265841655]\u001b[A\n",
      " 71%|                        | 71/100 [00:42<00:09,  3.13trial/s, best loss: 1.7385034265841655]\u001b[A\n",
      " 72%|                       | 72/100 [00:43<00:12,  2.20trial/s, best loss: 1.7385034265841655]\u001b[A\n",
      " 73%|                      | 73/100 [00:43<00:10,  2.51trial/s, best loss: 1.7385034265841655]\u001b[A\n",
      " 74%|                     | 74/100 [00:44<00:09,  2.64trial/s, best loss: 1.7385034265841655]\u001b[A\n",
      " 75%|                     | 75/100 [00:44<00:11,  2.25trial/s, best loss: 1.7385034265841655]\u001b[A\n",
      " 76%|                    | 76/100 [00:45<00:10,  2.23trial/s, best loss: 1.7385034265841655]\u001b[A\n",
      " 77%|                   | 77/100 [00:45<00:08,  2.78trial/s, best loss: 1.7385034265841655]\u001b[A\n",
      " 78%|                  | 78/100 [00:45<00:08,  2.73trial/s, best loss: 1.7385034265841655]\u001b[A\n",
      " 79%|                 | 79/100 [00:46<00:12,  1.73trial/s, best loss: 1.7385034265841655]\u001b[A\n",
      " 80%|                | 80/100 [00:47<00:10,  1.87trial/s, best loss: 1.7385034265841655]\u001b[A\n",
      " 81%|                | 81/100 [00:48<00:12,  1.56trial/s, best loss: 1.7385034265841655]\u001b[A\n",
      " 82%|               | 82/100 [00:48<00:12,  1.50trial/s, best loss: 1.7385034265841655]\u001b[A\n",
      " 83%|              | 83/100 [00:49<00:12,  1.34trial/s, best loss: 1.7385034265841655]\u001b[A\n",
      " 84%|             | 84/100 [00:50<00:11,  1.39trial/s, best loss: 1.7385034265841655]\u001b[A\n",
      " 85%|            | 85/100 [00:50<00:08,  1.86trial/s, best loss: 1.7385034265841655]\u001b[A\n",
      " 86%|           | 86/100 [00:51<00:08,  1.62trial/s, best loss: 1.7385034265841655]\u001b[A\n",
      " 87%|           | 87/100 [00:52<00:09,  1.31trial/s, best loss: 1.7385034265841655]\u001b[A\n",
      " 88%|          | 88/100 [00:53<00:09,  1.22trial/s, best loss: 1.7385034265841655]\u001b[A\n",
      " 89%|         | 89/100 [00:53<00:07,  1.38trial/s, best loss: 1.7385034265841655]\u001b[A\n",
      " 90%|        | 90/100 [00:54<00:06,  1.55trial/s, best loss: 1.7385034265841655]\u001b[A\n",
      " 91%|       | 91/100 [00:54<00:05,  1.76trial/s, best loss: 1.7385034265841655]\u001b[A\n",
      " 92%|      | 92/100 [00:55<00:05,  1.55trial/s, best loss: 1.7385034265841655]\u001b[A\n",
      " 93%|      | 93/100 [00:55<00:03,  1.98trial/s, best loss: 1.7385034265841655]\u001b[A\n",
      " 94%|     | 94/100 [00:55<00:02,  2.31trial/s, best loss: 1.7385034265841655]\u001b[A\n",
      " 95%|    | 95/100 [00:56<00:02,  1.83trial/s, best loss: 1.7385034265841655]\u001b[A\n",
      " 96%|   | 96/100 [00:57<00:02,  1.45trial/s, best loss: 1.7385034265841655]\u001b[A\n",
      " 97%|  | 97/100 [00:58<00:02,  1.43trial/s, best loss: 1.7385034265841655]\u001b[A\n",
      " 98%| | 98/100 [00:59<00:01,  1.47trial/s, best loss: 1.7385034265841655]\u001b[A\n",
      " 99%|| 99/100 [01:00<00:00,  1.26trial/s, best loss: 1.7385034265841655]\u001b[A\n",
      "100%|| 100/100 [01:00<00:00,  1.65trial/s, best loss: 1.7385034265841655]\u001b[A\n",
      "Best hyperparameter set for random_forest is {'max_depth': 17, 'n_estimators': 297}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1de87b03568482da6c7131e0d4e999a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Doing PCA(101):   0%|          | 0/1 [00:00<?, ?images/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing random_forest model...\n",
      "\n",
      "  0%|                                                                                                               | 0/100 [00:00<?, ?trial/s, best loss=?]\u001b[A\n",
      "  1%|                                                                                    | 1/100 [00:01<02:18,  1.40s/trial, best loss: 1.8080331106845509]\u001b[A\n",
      "  2%|                                                                                   | 2/100 [00:02<02:00,  1.23s/trial, best loss: 1.8080331106845509]\u001b[A\n",
      "  3%|                                                                                  | 3/100 [00:02<01:13,  1.33trial/s, best loss: 1.8080331106845509]\u001b[A\n",
      "  4%|                                                                                 | 4/100 [00:03<01:26,  1.11trial/s, best loss: 1.8080331106845509]\u001b[A\n",
      "  5%|                                                                                | 5/100 [00:04<01:03,  1.49trial/s, best loss: 1.8080331106845509]\u001b[A\n",
      "  6%|                                                                                | 6/100 [00:04<01:01,  1.52trial/s, best loss: 1.8080331106845509]\u001b[A\n",
      "  7%|                                                                               | 7/100 [00:05<00:52,  1.77trial/s, best loss: 1.8080331106845509]\u001b[A\n",
      "  8%|                                                                              | 8/100 [00:05<00:43,  2.11trial/s, best loss: 1.8080331106845509]\u001b[A\n",
      "  9%|                                                                             | 9/100 [00:06<01:04,  1.42trial/s, best loss: 1.8080331106845509]\u001b[A\n",
      " 10%|                                                                           | 10/100 [00:07<00:55,  1.62trial/s, best loss: 1.8080331106845509]\u001b[A\n",
      " 11%|                                                                          | 11/100 [00:07<00:43,  2.06trial/s, best loss: 1.8080331106845509]\u001b[A\n",
      " 12%|                                                                          | 12/100 [00:08<01:06,  1.32trial/s, best loss: 1.8056471648571553]\u001b[A\n",
      " 13%|                                                                         | 13/100 [00:09<01:01,  1.42trial/s, best loss: 1.8056471648571553]\u001b[A\n",
      " 14%|                                                                        | 14/100 [00:09<00:48,  1.77trial/s, best loss: 1.8056471648571553]\u001b[A\n",
      " 15%|                                                                       | 15/100 [00:09<00:46,  1.83trial/s, best loss: 1.8056471648571553]\u001b[A\n",
      " 16%|                                                                       | 16/100 [00:11<01:02,  1.35trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 17%|                                                                      | 17/100 [00:11<00:52,  1.58trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 18%|                                                                     | 18/100 [00:11<00:39,  2.08trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 19%|                                                                    | 19/100 [00:12<00:53,  1.51trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 20%|                                                                    | 20/100 [00:13<00:56,  1.42trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 21%|                                                                   | 21/100 [00:14<00:59,  1.32trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 22%|                                                                  | 22/100 [00:15<00:58,  1.34trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 23%|                                                                 | 23/100 [00:16<01:02,  1.24trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 24%|                                                                | 24/100 [00:16<00:46,  1.63trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 26%|                                                               | 26/100 [00:17<00:46,  1.61trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 27%|                                                              | 27/100 [00:17<00:38,  1.88trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 28%|                                                             | 28/100 [00:17<00:31,  2.25trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 29%|                                                            | 29/100 [00:19<00:45,  1.55trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 30%|                                                           | 30/100 [00:20<00:54,  1.27trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 31%|                                                          | 31/100 [00:21<00:58,  1.18trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 32%|                                                         | 32/100 [00:21<00:55,  1.23trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 33%|                                                         | 33/100 [00:22<00:48,  1.38trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 34%|                                                        | 34/100 [00:22<00:36,  1.81trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 35%|                                                       | 35/100 [00:23<00:33,  1.91trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 37%|                                                     | 37/100 [00:23<00:30,  2.04trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 39%|                                                   | 39/100 [00:24<00:20,  3.03trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 40%|                                                   | 40/100 [00:25<00:26,  2.25trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 41%|                                                  | 41/100 [00:25<00:33,  1.76trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 42%|                                                 | 42/100 [00:26<00:29,  1.99trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 43%|                                                | 43/100 [00:27<00:34,  1.66trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 44%|                                               | 44/100 [00:28<00:45,  1.24trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 45%|                                              | 45/100 [00:29<00:52,  1.04trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 46%|                                              | 46/100 [00:30<00:53,  1.00trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 47%|                                             | 47/100 [00:31<00:44,  1.20trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 48%|                                            | 48/100 [00:31<00:37,  1.40trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 49%|                                           | 49/100 [00:32<00:42,  1.20trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 50%|                                          | 50/100 [00:33<00:34,  1.45trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 51%|                                         | 51/100 [00:34<00:35,  1.38trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 52%|                                        | 52/100 [00:34<00:27,  1.72trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 53%|                                        | 53/100 [00:35<00:31,  1.49trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 54%|                                       | 54/100 [00:35<00:27,  1.69trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 55%|                                      | 55/100 [00:35<00:22,  1.99trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 56%|                                     | 56/100 [00:36<00:21,  2.05trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 57%|                                    | 57/100 [00:37<00:27,  1.57trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 58%|                                   | 58/100 [00:38<00:31,  1.33trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 59%|                                  | 59/100 [00:39<00:31,  1.32trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 60%|                                  | 60/100 [00:40<00:34,  1.16trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 61%|                                 | 61/100 [00:41<00:37,  1.04trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 62%|                                | 62/100 [00:42<00:37,  1.02trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 63%|                               | 63/100 [00:43<00:36,  1.03trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 64%|                              | 64/100 [00:43<00:30,  1.19trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 65%|                             | 65/100 [00:44<00:28,  1.23trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 66%|                             | 66/100 [00:45<00:25,  1.33trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 67%|                            | 67/100 [00:46<00:26,  1.26trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 68%|                           | 68/100 [00:47<00:31,  1.03trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 69%|                          | 69/100 [00:47<00:24,  1.26trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 70%|                         | 70/100 [00:49<00:28,  1.05trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 71%|                        | 71/100 [00:50<00:25,  1.12trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 72%|                       | 72/100 [00:51<00:28,  1.01s/trial, best loss: 1.805466604112161]\u001b[A\n",
      " 73%|                       | 73/100 [00:52<00:26,  1.04trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 74%|                      | 74/100 [00:52<00:19,  1.36trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 75%|                     | 75/100 [00:53<00:20,  1.20trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 76%|                    | 76/100 [00:54<00:18,  1.28trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 77%|                   | 77/100 [00:54<00:17,  1.32trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 78%|                  | 78/100 [00:56<00:19,  1.11trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 79%|                 | 79/100 [00:56<00:16,  1.29trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 80%|                 | 80/100 [00:57<00:15,  1.32trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 81%|                | 81/100 [00:57<00:12,  1.53trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 82%|               | 82/100 [00:58<00:12,  1.45trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 84%|             | 84/100 [00:59<00:08,  1.80trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 85%|            | 85/100 [00:59<00:08,  1.68trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 86%|            | 86/100 [01:00<00:09,  1.55trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 87%|           | 87/100 [01:01<00:08,  1.46trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 88%|          | 88/100 [01:02<00:09,  1.32trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 89%|         | 89/100 [01:03<00:09,  1.21trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 90%|        | 90/100 [01:04<00:08,  1.22trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 91%|       | 91/100 [01:05<00:08,  1.03trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 92%|      | 92/100 [01:05<00:06,  1.25trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 93%|      | 93/100 [01:06<00:05,  1.35trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 94%|     | 94/100 [01:06<00:03,  1.64trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 95%|    | 95/100 [01:07<00:02,  1.91trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 96%|   | 96/100 [01:07<00:01,  2.05trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 97%|  | 97/100 [01:07<00:01,  2.58trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 98%| | 98/100 [01:08<00:01,  1.90trial/s, best loss: 1.805466604112161]\u001b[A\n",
      " 99%|| 99/100 [01:10<00:00,  1.27trial/s, best loss: 1.8044738777633864]\u001b[A\n",
      "100%|| 100/100 [01:11<00:00,  1.41trial/s, best loss: 1.8044738777633864]\u001b[A\n",
      "Best hyperparameter set for random_forest is {'max_depth': 18, 'n_estimators': 293}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2007d867763a45c1a11a28f3b8f98483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Doing PCA(151):   0%|          | 0/1 [00:00<?, ?images/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing random_forest model...\n",
      "\n",
      "  0%|                                                                                                               | 0/100 [00:00<?, ?trial/s, best loss=?]\u001b[A\n",
      "  1%|                                                                                    | 1/100 [00:00<00:30,  3.29trial/s, best loss: 1.9868634325525547]\u001b[A\n",
      "  2%|                                                                                    | 2/100 [00:01<01:10,  1.39trial/s, best loss: 1.883946506471883]\u001b[A\n",
      "  3%|                                                                                   | 3/100 [00:01<00:42,  2.27trial/s, best loss: 1.883946506471883]\u001b[A\n",
      "  4%|                                                                                 | 4/100 [00:02<00:57,  1.66trial/s, best loss: 1.8740352736887627]\u001b[A\n",
      "  5%|                                                                                | 5/100 [00:03<01:03,  1.49trial/s, best loss: 1.8740352736887627]\u001b[A\n",
      "  6%|                                                                                | 6/100 [00:03<00:51,  1.81trial/s, best loss: 1.8740352736887627]\u001b[A\n",
      "  7%|                                                                               | 7/100 [00:03<00:49,  1.86trial/s, best loss: 1.8740352736887627]\u001b[A\n",
      "  9%|                                                                             | 9/100 [00:04<00:34,  2.60trial/s, best loss: 1.8740352736887627]\u001b[A\n",
      " 10%|                                                                           | 10/100 [00:04<00:32,  2.74trial/s, best loss: 1.8740352736887627]\u001b[A\n",
      " 11%|                                                                          | 11/100 [00:04<00:29,  3.00trial/s, best loss: 1.8740352736887627]\u001b[A\n",
      " 12%|                                                                          | 12/100 [00:05<00:26,  3.35trial/s, best loss: 1.8740352736887627]\u001b[A\n",
      " 13%|                                                                         | 13/100 [00:05<00:28,  3.05trial/s, best loss: 1.8740352736887627]\u001b[A\n",
      " 14%|                                                                        | 14/100 [00:06<00:44,  1.95trial/s, best loss: 1.8731331813000676]\u001b[A\n",
      " 15%|                                                                       | 15/100 [00:07<01:07,  1.26trial/s, best loss: 1.8731331813000676]\u001b[A\n",
      " 16%|                                                                      | 16/100 [00:08<00:57,  1.46trial/s, best loss: 1.8731331813000676]\u001b[A\n",
      " 17%|                                                                     | 17/100 [00:09<01:07,  1.23trial/s, best loss: 1.8731331813000676]\u001b[A\n",
      " 18%|                                                                     | 18/100 [00:10<01:04,  1.27trial/s, best loss: 1.8731331813000676]\u001b[A\n",
      " 20%|                                                                   | 20/100 [00:10<00:37,  2.16trial/s, best loss: 1.8731331813000676]\u001b[A\n",
      " 21%|                                                                  | 21/100 [00:10<00:29,  2.66trial/s, best loss: 1.8731331813000676]\u001b[A\n",
      " 22%|                                                                 | 22/100 [00:11<00:42,  1.83trial/s, best loss: 1.8731331813000676]\u001b[A\n",
      " 23%|                                                                | 23/100 [00:12<00:48,  1.59trial/s, best loss: 1.8731331813000676]\u001b[A\n",
      " 24%|                                                               | 24/100 [00:12<00:45,  1.68trial/s, best loss: 1.8731331813000676]\u001b[A\n",
      " 25%|                                                               | 25/100 [00:13<00:38,  1.96trial/s, best loss: 1.8731331813000676]\u001b[A\n",
      " 26%|                                                              | 26/100 [00:14<00:59,  1.24trial/s, best loss: 1.8646028776263488]\u001b[A\n",
      " 27%|                                                             | 27/100 [00:15<01:02,  1.18trial/s, best loss: 1.8646028776263488]\u001b[A\n",
      " 28%|                                                            | 28/100 [00:16<01:03,  1.13trial/s, best loss: 1.8646028776263488]\u001b[A\n",
      " 29%|                                                           | 29/100 [00:18<01:17,  1.09s/trial, best loss: 1.8646028776263486]\u001b[A\n",
      " 30%|                                                          | 30/100 [00:18<01:00,  1.16trial/s, best loss: 1.8646028776263486]\u001b[A\n",
      " 31%|                                                          | 31/100 [00:19<01:00,  1.15trial/s, best loss: 1.8646028776263486]\u001b[A\n",
      " 32%|                                                         | 32/100 [00:20<01:10,  1.04s/trial, best loss: 1.8640344185892221]\u001b[A\n",
      " 33%|                                                        | 33/100 [00:21<00:58,  1.14trial/s, best loss: 1.8640344185892221]\u001b[A\n",
      " 34%|                                                       | 34/100 [00:22<01:12,  1.10s/trial, best loss: 1.8640344185892221]\u001b[A\n",
      " 35%|                                                      | 35/100 [00:23<01:07,  1.04s/trial, best loss: 1.8640344185892221]\u001b[A\n",
      " 36%|                                                     | 36/100 [00:24<00:59,  1.07trial/s, best loss: 1.8640344185892221]\u001b[A\n",
      " 37%|                                                     | 37/100 [00:25<01:04,  1.02s/trial, best loss: 1.8640344185892221]\u001b[A\n",
      " 38%|                                                    | 38/100 [00:26<00:48,  1.28trial/s, best loss: 1.8640344185892221]\u001b[A\n",
      " 40%|                                                  | 40/100 [00:27<00:42,  1.41trial/s, best loss: 1.8640344185892221]\u001b[A\n",
      " 41%|                                                 | 41/100 [00:28<00:43,  1.35trial/s, best loss: 1.8640344185892221]\u001b[A\n",
      " 42%|                                                | 42/100 [00:28<00:33,  1.73trial/s, best loss: 1.8640344185892221]\u001b[A\n",
      " 43%|                                                | 43/100 [00:28<00:25,  2.20trial/s, best loss: 1.8640344185892221]\u001b[A\n",
      " 44%|                                               | 44/100 [00:28<00:21,  2.57trial/s, best loss: 1.8640344185892221]\u001b[A\n",
      " 45%|                                              | 45/100 [00:29<00:36,  1.49trial/s, best loss: 1.8640344185892221]\u001b[A\n",
      " 46%|                                             | 46/100 [00:31<00:48,  1.12trial/s, best loss: 1.8640344185892221]\u001b[A\n",
      " 47%|                                            | 47/100 [00:32<00:55,  1.05s/trial, best loss: 1.8640344185892221]\u001b[A\n",
      " 48%|                                           | 48/100 [00:34<00:59,  1.14s/trial, best loss: 1.8640344185892221]\u001b[A\n",
      " 49%|                                          | 49/100 [00:35<01:04,  1.27s/trial, best loss: 1.8640344185892221]\u001b[A\n",
      " 50%|                                          | 50/100 [00:36<00:53,  1.07s/trial, best loss: 1.8640344185892221]\u001b[A\n",
      " 51%|                                         | 51/100 [00:37<00:55,  1.13s/trial, best loss: 1.8640344185892221]\u001b[A\n",
      " 52%|                                        | 52/100 [00:38<00:49,  1.03s/trial, best loss: 1.8640344185892221]\u001b[A\n",
      " 53%|                                       | 53/100 [00:39<00:45,  1.04trial/s, best loss: 1.8640344185892221]\u001b[A\n",
      " 55%|                                     | 55/100 [00:39<00:28,  1.56trial/s, best loss: 1.8640344185892221]\u001b[A\n",
      " 57%|                                    | 57/100 [00:40<00:25,  1.68trial/s, best loss: 1.8640344185892221]\u001b[A\n",
      " 58%|                                   | 58/100 [00:41<00:25,  1.63trial/s, best loss: 1.8640344185892221]\u001b[A\n",
      " 59%|                                  | 59/100 [00:42<00:29,  1.37trial/s, best loss: 1.8640344185892221]\u001b[A\n",
      " 60%|                                 | 60/100 [00:42<00:24,  1.62trial/s, best loss: 1.8640344185892221]\u001b[A\n",
      " 61%|                                | 61/100 [00:43<00:28,  1.36trial/s, best loss: 1.8640344185892221]\u001b[A\n",
      " 62%|                                | 62/100 [00:44<00:24,  1.55trial/s, best loss: 1.8640344185892221]\u001b[A\n",
      " 63%|                               | 63/100 [00:44<00:20,  1.84trial/s, best loss: 1.8640344185892221]\u001b[A\n",
      " 64%|                              | 64/100 [00:45<00:19,  1.87trial/s, best loss: 1.8640344185892221]\u001b[A\n",
      " 66%|                            | 66/100 [00:46<00:21,  1.57trial/s, best loss: 1.8640344185892221]\u001b[A\n",
      " 67%|                           | 67/100 [00:46<00:17,  1.89trial/s, best loss: 1.8640344185892221]\u001b[A\n",
      " 68%|                           | 68/100 [00:47<00:15,  2.10trial/s, best loss: 1.8640344185892221]\u001b[A\n",
      " 69%|                          | 69/100 [00:47<00:12,  2.50trial/s, best loss: 1.8640344185892221]\u001b[A\n",
      " 70%|                         | 70/100 [00:48<00:20,  1.48trial/s, best loss: 1.8640344185892221]\u001b[A\n",
      " 71%|                        | 71/100 [00:49<00:24,  1.20trial/s, best loss: 1.8640344185892221]\u001b[A\n",
      " 72%|                       | 72/100 [00:50<00:24,  1.13trial/s, best loss: 1.8640344185892221]\u001b[A\n",
      " 73%|                      | 73/100 [00:52<00:26,  1.01trial/s, best loss: 1.8640344185892221]\u001b[A\n",
      " 74%|                     | 74/100 [00:53<00:24,  1.05trial/s, best loss: 1.8640344185892221]\u001b[A\n",
      " 75%|                     | 75/100 [00:53<00:21,  1.16trial/s, best loss: 1.8640344185892221]\u001b[A\n",
      " 76%|                    | 76/100 [00:55<00:24,  1.02s/trial, best loss: 1.8640344185892221]\u001b[A\n",
      " 77%|                   | 77/100 [00:56<00:23,  1.02s/trial, best loss: 1.8640344185892221]\u001b[A\n",
      " 78%|                  | 78/100 [00:57<00:25,  1.14s/trial, best loss: 1.8640344185892221]\u001b[A\n",
      " 79%|                 | 79/100 [00:58<00:23,  1.10s/trial, best loss: 1.8640344185892221]\u001b[A\n",
      " 80%|                | 80/100 [00:59<00:18,  1.06trial/s, best loss: 1.8640344185892221]\u001b[A\n",
      " 81%|                | 81/100 [01:00<00:21,  1.14s/trial, best loss: 1.8640344185892221]\u001b[A\n",
      " 82%|               | 82/100 [01:01<00:15,  1.13trial/s, best loss: 1.8640344185892221]\u001b[A\n",
      " 83%|              | 83/100 [01:02<00:15,  1.07trial/s, best loss: 1.8640344185892221]\u001b[A\n",
      " 84%|             | 84/100 [01:02<00:13,  1.22trial/s, best loss: 1.8640344185892221]\u001b[A\n",
      " 86%|           | 86/100 [01:03<00:10,  1.37trial/s, best loss: 1.8640344185892221]\u001b[A\n",
      " 87%|           | 87/100 [01:05<00:11,  1.15trial/s, best loss: 1.8640344185892221]\u001b[A\n",
      " 88%|          | 88/100 [01:06<00:11,  1.04trial/s, best loss: 1.8640344185892221]\u001b[A\n",
      " 89%|         | 89/100 [01:06<00:09,  1.21trial/s, best loss: 1.8640344185892221]\u001b[A\n",
      " 91%|       | 91/100 [01:07<00:04,  1.80trial/s, best loss: 1.8640344185892221]\u001b[A\n",
      " 92%|      | 92/100 [01:07<00:04,  1.98trial/s, best loss: 1.8640344185892221]\u001b[A\n",
      " 93%|      | 93/100 [01:08<00:04,  1.68trial/s, best loss: 1.8640344185892221]\u001b[A\n",
      " 94%|     | 94/100 [01:08<00:02,  2.14trial/s, best loss: 1.8640344185892221]\u001b[A\n",
      " 95%|    | 95/100 [01:10<00:03,  1.29trial/s, best loss: 1.8640344185892221]\u001b[A\n",
      " 96%|   | 96/100 [01:10<00:02,  1.34trial/s, best loss: 1.8640344185892221]\u001b[A\n",
      " 97%|  | 97/100 [01:12<00:02,  1.14trial/s, best loss: 1.8640344185892221]\u001b[A\n",
      " 98%| | 98/100 [01:13<00:02,  1.02s/trial, best loss: 1.8640344185892221]\u001b[A\n",
      " 99%|| 99/100 [01:14<00:01,  1.06s/trial, best loss: 1.8640344185892221]\u001b[A\n",
      "100%|| 100/100 [01:15<00:00,  1.32trial/s, best loss: 1.8640344185892221]\u001b[A\n",
      "Best hyperparameter set for random_forest is {'max_depth': 16, 'n_estimators': 262}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d9c144be41947009288d124a4b54ef7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Doing PCA(201):   0%|          | 0/1 [00:00<?, ?images/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing random_forest model...\n",
      "\n",
      "  0%|                                                                                                               | 0/100 [00:00<?, ?trial/s, best loss=?]\u001b[A\n",
      "  1%|                                                                                    | 1/100 [00:01<01:46,  1.08s/trial, best loss: 1.9987402434690456]\u001b[A\n",
      "  2%|                                                                                   | 2/100 [00:01<01:04,  1.51trial/s, best loss: 1.9987402434690456]\u001b[A\n",
      "  3%|                                                                                  | 3/100 [00:02<01:09,  1.39trial/s, best loss: 1.9987402434690456]\u001b[A\n",
      "  4%|                                                                                 | 4/100 [00:03<01:38,  1.03s/trial, best loss: 1.9215881188789872]\u001b[A\n",
      "  5%|                                                                                | 5/100 [00:04<01:11,  1.33trial/s, best loss: 1.9215881188789872]\u001b[A\n",
      "  6%|                                                                                | 6/100 [00:04<01:00,  1.55trial/s, best loss: 1.9215881188789872]\u001b[A\n",
      "  7%|                                                                               | 7/100 [00:05<01:06,  1.39trial/s, best loss: 1.9215881188789872]\u001b[A\n",
      "  8%|                                                                              | 8/100 [00:05<01:03,  1.45trial/s, best loss: 1.9215881188789872]\u001b[A\n",
      "  9%|                                                                             | 9/100 [00:07<01:29,  1.01trial/s, best loss: 1.9188634228409032]\u001b[A\n",
      " 10%|                                                                           | 10/100 [00:07<01:09,  1.30trial/s, best loss: 1.9188634228409032]\u001b[A\n",
      " 11%|                                                                          | 11/100 [00:09<01:32,  1.04s/trial, best loss: 1.9177955739149983]\u001b[A\n",
      " 12%|                                                                          | 12/100 [00:10<01:19,  1.10trial/s, best loss: 1.9177955739149983]\u001b[A\n",
      " 13%|                                                                         | 13/100 [00:11<01:34,  1.09s/trial, best loss: 1.9177955739149983]\u001b[A\n",
      " 14%|                                                                        | 14/100 [00:12<01:15,  1.13trial/s, best loss: 1.9177955739149983]\u001b[A\n",
      " 15%|                                                                       | 15/100 [00:12<00:57,  1.49trial/s, best loss: 1.9177955739149983]\u001b[A\n",
      " 16%|                                                                      | 16/100 [00:12<00:45,  1.86trial/s, best loss: 1.9177955739149983]\u001b[A\n",
      " 18%|                                                                     | 18/100 [00:12<00:26,  3.05trial/s, best loss: 1.9177955739149983]\u001b[A\n",
      " 19%|                                                                    | 19/100 [00:13<00:36,  2.19trial/s, best loss: 1.9177955739149983]\u001b[A\n",
      " 20%|                                                                   | 20/100 [00:14<00:43,  1.84trial/s, best loss: 1.9177955739149983]\u001b[A\n",
      " 21%|                                                                  | 21/100 [00:15<01:06,  1.19trial/s, best loss: 1.9177955739149983]\u001b[A\n",
      " 22%|                                                                 | 22/100 [00:17<01:23,  1.07s/trial, best loss: 1.9177955739149983]\u001b[A\n",
      " 23%|                                                                | 23/100 [00:18<01:29,  1.16s/trial, best loss: 1.9177955739149983]\u001b[A\n",
      " 24%|                                                               | 24/100 [00:20<01:30,  1.20s/trial, best loss: 1.9177955739149983]\u001b[A\n",
      " 25%|                                                               | 25/100 [00:20<01:20,  1.08s/trial, best loss: 1.9177955739149983]\u001b[A\n",
      " 26%|                                                              | 26/100 [00:22<01:28,  1.20s/trial, best loss: 1.9177955739149983]\u001b[A\n",
      " 27%|                                                             | 27/100 [00:24<01:36,  1.32s/trial, best loss: 1.9177955739149983]\u001b[A\n",
      " 28%|                                                            | 28/100 [00:25<01:38,  1.37s/trial, best loss: 1.9177955739149983]\u001b[A\n",
      " 29%|                                                           | 29/100 [00:25<01:10,  1.00trial/s, best loss: 1.9177955739149983]\u001b[A\n",
      " 30%|                                                          | 30/100 [00:25<00:55,  1.27trial/s, best loss: 1.9177955739149983]\u001b[A\n",
      " 31%|                                                          | 31/100 [00:27<01:10,  1.03s/trial, best loss: 1.9177955739149983]\u001b[A\n",
      " 32%|                                                         | 32/100 [00:28<01:15,  1.11s/trial, best loss: 1.9109133126020563]\u001b[A\n",
      " 33%|                                                        | 33/100 [00:29<01:13,  1.10s/trial, best loss: 1.9109133126020563]\u001b[A\n",
      " 35%|                                                      | 35/100 [00:30<00:47,  1.38trial/s, best loss: 1.9109133126020563]\u001b[A\n",
      " 36%|                                                     | 36/100 [00:31<00:55,  1.15trial/s, best loss: 1.9109133126020563]\u001b[A\n",
      " 37%|                                                     | 37/100 [00:33<00:59,  1.05trial/s, best loss: 1.9109133126020563]\u001b[A\n",
      " 38%|                                                    | 38/100 [00:34<01:06,  1.07s/trial, best loss: 1.9109133126020563]\u001b[A\n",
      " 39%|                                                   | 39/100 [00:34<00:49,  1.24trial/s, best loss: 1.9109133126020563]\u001b[A\n",
      " 40%|                                                  | 40/100 [00:35<00:48,  1.23trial/s, best loss: 1.9109133126020563]\u001b[A\n",
      " 41%|                                                 | 41/100 [00:36<00:54,  1.08trial/s, best loss: 1.9109133126020563]\u001b[A\n",
      " 42%|                                                | 42/100 [00:37<00:52,  1.11trial/s, best loss: 1.9109133126020563]\u001b[A\n",
      " 43%|                                                | 43/100 [00:37<00:45,  1.25trial/s, best loss: 1.9109133126020563]\u001b[A\n",
      " 44%|                                               | 44/100 [00:38<00:36,  1.54trial/s, best loss: 1.9109133126020563]\u001b[A\n",
      " 45%|                                              | 45/100 [00:38<00:30,  1.82trial/s, best loss: 1.9109133126020563]\u001b[A\n",
      " 46%|                                             | 46/100 [00:39<00:32,  1.64trial/s, best loss: 1.9109133126020563]\u001b[A\n",
      " 47%|                                            | 47/100 [00:40<00:38,  1.39trial/s, best loss: 1.9109133126020563]\u001b[A\n",
      " 48%|                                           | 48/100 [00:40<00:31,  1.65trial/s, best loss: 1.9109133126020563]\u001b[A\n",
      " 49%|                                          | 49/100 [00:41<00:29,  1.74trial/s, best loss: 1.9109133126020563]\u001b[A\n",
      " 50%|                                          | 50/100 [00:41<00:28,  1.75trial/s, best loss: 1.9109133126020563]\u001b[A\n",
      " 51%|                                         | 51/100 [00:42<00:38,  1.29trial/s, best loss: 1.9109133126020563]\u001b[A\n",
      " 52%|                                        | 52/100 [00:43<00:32,  1.49trial/s, best loss: 1.9109133126020563]\u001b[A\n",
      " 53%|                                       | 53/100 [00:44<00:32,  1.44trial/s, best loss: 1.9109133126020563]\u001b[A\n",
      " 54%|                                      | 54/100 [00:44<00:26,  1.73trial/s, best loss: 1.9109133126020563]\u001b[A\n",
      " 55%|                                     | 55/100 [00:46<00:41,  1.08trial/s, best loss: 1.9109133126020563]\u001b[A\n",
      " 56%|                                     | 56/100 [00:47<00:45,  1.03s/trial, best loss: 1.9109133126020563]\u001b[A\n",
      " 57%|                                    | 57/100 [00:47<00:33,  1.29trial/s, best loss: 1.9109133126020563]\u001b[A\n",
      " 58%|                                   | 58/100 [00:48<00:36,  1.16trial/s, best loss: 1.9109133126020563]\u001b[A\n",
      " 59%|                                  | 59/100 [00:49<00:30,  1.33trial/s, best loss: 1.9109133126020563]\u001b[A\n",
      " 60%|                                 | 60/100 [00:50<00:33,  1.20trial/s, best loss: 1.9109133126020563]\u001b[A\n",
      " 62%|                                | 62/100 [00:50<00:19,  1.95trial/s, best loss: 1.9109133126020563]\u001b[A\n",
      " 63%|                               | 63/100 [00:50<00:16,  2.19trial/s, best loss: 1.9109133126020563]\u001b[A\n",
      " 64%|                              | 64/100 [00:51<00:15,  2.29trial/s, best loss: 1.9109133126020563]\u001b[A\n",
      " 65%|                             | 65/100 [00:52<00:26,  1.31trial/s, best loss: 1.9109133126020563]\u001b[A\n",
      " 66%|                            | 66/100 [00:53<00:24,  1.41trial/s, best loss: 1.9109133126020563]\u001b[A\n",
      " 67%|                           | 67/100 [00:54<00:23,  1.38trial/s, best loss: 1.9109133126020563]\u001b[A\n",
      " 68%|                           | 68/100 [00:55<00:28,  1.14trial/s, best loss: 1.9087460618499805]\u001b[A\n",
      " 69%|                          | 69/100 [00:55<00:23,  1.30trial/s, best loss: 1.9087460618499805]\u001b[A\n",
      " 70%|                         | 70/100 [00:56<00:21,  1.42trial/s, best loss: 1.9087460618499805]\u001b[A\n",
      " 71%|                        | 71/100 [00:58<00:29,  1.02s/trial, best loss: 1.9087460618499805]\u001b[A\n",
      " 72%|                       | 72/100 [00:59<00:29,  1.05s/trial, best loss: 1.9087460618499805]\u001b[A\n",
      " 73%|                      | 73/100 [01:00<00:29,  1.11s/trial, best loss: 1.9087460618499805]\u001b[A\n",
      " 74%|                     | 74/100 [01:01<00:30,  1.17s/trial, best loss: 1.9087460618499805]\u001b[A\n",
      " 76%|                    | 76/100 [01:02<00:18,  1.28trial/s, best loss: 1.9087460618499805]\u001b[A\n",
      " 77%|                   | 77/100 [01:04<00:21,  1.05trial/s, best loss: 1.9087460618499805]\u001b[A\n",
      " 78%|                  | 78/100 [01:05<00:25,  1.16s/trial, best loss: 1.9087460618499805]\u001b[A\n",
      " 79%|                 | 79/100 [01:06<00:21,  1.04s/trial, best loss: 1.9087460618499805]\u001b[A\n",
      " 80%|                | 80/100 [01:07<00:20,  1.03s/trial, best loss: 1.9087460618499805]\u001b[A\n",
      " 81%|                | 81/100 [01:08<00:18,  1.04trial/s, best loss: 1.9087460618499805]\u001b[A\n",
      " 82%|               | 82/100 [01:09<00:18,  1.05s/trial, best loss: 1.9087460618499805]\u001b[A\n",
      " 83%|              | 83/100 [01:10<00:14,  1.14trial/s, best loss: 1.9087460618499805]\u001b[A\n",
      " 85%|            | 85/100 [01:11<00:10,  1.38trial/s, best loss: 1.9087460618499805]\u001b[A\n",
      " 86%|           | 86/100 [01:12<00:13,  1.03trial/s, best loss: 1.9087460618499805]\u001b[A\n",
      " 87%|           | 87/100 [01:13<00:11,  1.10trial/s, best loss: 1.9087460618499805]\u001b[A\n",
      " 88%|          | 88/100 [01:14<00:12,  1.01s/trial, best loss: 1.9087460618499805]\u001b[A\n",
      " 89%|         | 89/100 [01:15<00:09,  1.12trial/s, best loss: 1.9087460618499805]\u001b[A\n",
      " 90%|        | 90/100 [01:16<00:08,  1.12trial/s, best loss: 1.9087460618499805]\u001b[A\n",
      " 91%|       | 91/100 [01:17<00:08,  1.06trial/s, best loss: 1.9087460618499805]\u001b[A\n",
      " 92%|      | 92/100 [01:17<00:06,  1.19trial/s, best loss: 1.9087460618499805]\u001b[A\n",
      " 93%|      | 93/100 [01:18<00:04,  1.52trial/s, best loss: 1.9087460618499805]\u001b[A\n",
      " 94%|     | 94/100 [01:18<00:03,  1.60trial/s, best loss: 1.9087460618499805]\u001b[A\n",
      " 95%|    | 95/100 [01:19<00:03,  1.54trial/s, best loss: 1.9087460618499805]\u001b[A\n",
      " 96%|   | 96/100 [01:20<00:03,  1.24trial/s, best loss: 1.9087460618499805]\u001b[A\n",
      " 97%|  | 97/100 [01:20<00:01,  1.58trial/s, best loss: 1.9087460618499805]\u001b[A\n",
      " 98%| | 98/100 [01:21<00:01,  1.60trial/s, best loss: 1.9087460618499805]\u001b[A\n",
      " 99%|| 99/100 [01:22<00:00,  1.61trial/s, best loss: 1.9087460618499805]\u001b[A\n",
      "100%|| 100/100 [01:22<00:00,  1.21trial/s, best loss: 1.9087460618499805]\u001b[A\n",
      "Best hyperparameter set for random_forest is {'max_depth': 17, 'n_estimators': 201}\n",
      "\n",
      "\n",
      "Optimizing random_forest model...\n",
      "\n",
      "  0%|                                                                                                               | 0/100 [00:00<?, ?trial/s, best loss=?]\u001b[A\n",
      "  1%|                                                                                     | 1/100 [00:03<05:25,  3.29s/trial, best loss: 2.141212969482355]\u001b[A\n",
      "  2%|                                                                                    | 2/100 [00:04<03:06,  1.90s/trial, best loss: 2.141212969482355]\u001b[A\n",
      "  3%|                                                                                   | 3/100 [00:07<03:50,  2.37s/trial, best loss: 2.141212969482355]\u001b[A\n",
      "  4%|                                                                                  | 4/100 [00:08<02:51,  1.79s/trial, best loss: 2.141212969482355]\u001b[A\n",
      "  5%|                                                                                 | 5/100 [00:10<03:24,  2.15s/trial, best loss: 2.141212969482355]\u001b[A\n",
      "  6%|                                                                                 | 6/100 [00:17<05:35,  3.57s/trial, best loss: 2.09637689522046]\u001b[A\n",
      "  7%|                                                                                 | 7/100 [00:18<04:24,  2.85s/trial, best loss: 2.09637689522046]\u001b[A\n",
      "  8%|                                                                                | 8/100 [00:23<05:33,  3.62s/trial, best loss: 2.09637689522046]\u001b[A\n",
      "  9%|                                                                               | 9/100 [00:30<06:43,  4.44s/trial, best loss: 2.09637689522046]\u001b[A\n",
      " 10%|                                                                             | 10/100 [00:33<06:19,  4.21s/trial, best loss: 2.09637689522046]\u001b[A\n",
      " 11%|                                                                            | 11/100 [00:39<07:02,  4.75s/trial, best loss: 2.09637689522046]\u001b[A\n",
      " 12%|                                                                           | 12/100 [00:45<07:17,  4.97s/trial, best loss: 2.09637689522046]\u001b[A\n",
      " 13%|                                                                          | 13/100 [00:47<05:49,  4.02s/trial, best loss: 2.09637689522046]\u001b[A\n",
      " 14%|                                                                          | 14/100 [00:51<06:06,  4.26s/trial, best loss: 2.09637689522046]\u001b[A\n",
      " 15%|                                                                         | 15/100 [00:53<04:42,  3.33s/trial, best loss: 2.09637689522046]\u001b[A\n",
      " 16%|                                                                        | 16/100 [00:54<04:03,  2.90s/trial, best loss: 2.09637689522046]\u001b[A\n",
      " 17%|                                                                       | 17/100 [00:58<04:05,  2.96s/trial, best loss: 2.09637689522046]\u001b[A\n",
      " 18%|                                                                      | 18/100 [01:03<04:52,  3.57s/trial, best loss: 2.09637689522046]\u001b[A\n",
      " 19%|                                                                     | 19/100 [01:07<05:23,  3.99s/trial, best loss: 2.09637689522046]\u001b[A\n",
      " 20%|                                                                    | 20/100 [01:14<06:24,  4.80s/trial, best loss: 2.09637689522046]\u001b[A\n",
      " 21%|                                                                    | 21/100 [01:18<06:07,  4.65s/trial, best loss: 2.09637689522046]\u001b[A\n",
      " 22%|                                                                   | 22/100 [01:25<06:42,  5.15s/trial, best loss: 2.09637689522046]\u001b[A\n",
      " 23%|                                                                  | 23/100 [01:29<06:05,  4.74s/trial, best loss: 2.09637689522046]\u001b[A\n",
      " 24%|                                                                 | 24/100 [01:31<05:17,  4.17s/trial, best loss: 2.09637689522046]\u001b[A\n",
      " 25%|                                                                | 25/100 [01:37<05:51,  4.69s/trial, best loss: 2.09637689522046]\u001b[A\n",
      " 26%|                                                               | 26/100 [01:44<06:23,  5.19s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 27%|                                                              | 27/100 [01:45<05:00,  4.12s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 28%|                                                              | 28/100 [01:51<05:29,  4.57s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 29%|                                                             | 29/100 [01:53<04:38,  3.92s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 30%|                                                            | 30/100 [02:00<05:26,  4.66s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 31%|                                                           | 31/100 [02:03<04:48,  4.18s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 32%|                                                          | 32/100 [02:06<04:25,  3.90s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 33%|                                                         | 33/100 [02:12<05:08,  4.60s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 34%|                                                        | 34/100 [02:18<05:17,  4.81s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 35%|                                                        | 35/100 [02:21<04:53,  4.51s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 36%|                                                       | 36/100 [02:26<04:51,  4.56s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 37%|                                                      | 37/100 [02:29<04:24,  4.21s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 38%|                                                     | 38/100 [02:35<04:51,  4.70s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 39%|                                                    | 39/100 [02:41<05:06,  5.02s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 40%|                                                   | 40/100 [02:45<04:35,  4.59s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 41%|                                                  | 41/100 [02:51<05:00,  5.09s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 42%|                                                  | 42/100 [02:55<04:30,  4.66s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 43%|                                                 | 43/100 [03:00<04:38,  4.88s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 44%|                                                | 44/100 [03:01<03:31,  3.77s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 45%|                                               | 45/100 [03:07<04:06,  4.48s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 46%|                                              | 46/100 [03:12<04:06,  4.56s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 47%|                                             | 47/100 [03:15<03:36,  4.08s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 48%|                                            | 48/100 [03:17<02:55,  3.38s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 49%|                                           | 49/100 [03:21<03:00,  3.53s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 50%|                                           | 50/100 [03:27<03:46,  4.53s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 51%|                                          | 51/100 [03:28<02:48,  3.45s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 52%|                                         | 52/100 [03:31<02:30,  3.13s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 53%|                                        | 53/100 [03:33<02:18,  2.94s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 54%|                                       | 54/100 [03:39<02:54,  3.79s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 55%|                                      | 55/100 [03:44<03:11,  4.25s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 56%|                                     | 56/100 [03:46<02:33,  3.48s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 57%|                                     | 57/100 [03:48<02:09,  3.01s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 58%|                                    | 58/100 [03:52<02:25,  3.46s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 59%|                                   | 59/100 [03:58<02:44,  4.00s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 60%|                                  | 60/100 [04:04<03:05,  4.64s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 61%|                                 | 61/100 [04:10<03:23,  5.21s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 62%|                                | 62/100 [04:12<02:41,  4.25s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 63%|                               | 63/100 [04:15<02:21,  3.84s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 64%|                               | 64/100 [04:21<02:40,  4.46s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 65%|                              | 65/100 [04:25<02:30,  4.31s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 66%|                             | 66/100 [04:29<02:18,  4.09s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 67%|                            | 67/100 [04:34<02:22,  4.32s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 68%|                           | 68/100 [04:40<02:36,  4.88s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 69%|                          | 69/100 [04:46<02:44,  5.29s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 70%|                         | 70/100 [04:50<02:22,  4.75s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 71%|                         | 71/100 [04:56<02:32,  5.26s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 72%|                        | 72/100 [05:02<02:36,  5.61s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 73%|                       | 73/100 [05:04<02:02,  4.53s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 74%|                      | 74/100 [05:06<01:31,  3.51s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 75%|                     | 75/100 [05:08<01:20,  3.23s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 76%|                    | 76/100 [05:10<01:05,  2.72s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 77%|                   | 77/100 [05:15<01:18,  3.41s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 78%|                   | 78/100 [05:21<01:32,  4.21s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 79%|                  | 79/100 [05:25<01:27,  4.16s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 80%|                 | 80/100 [05:28<01:17,  3.86s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 81%|                | 81/100 [05:32<01:12,  3.82s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 82%|               | 82/100 [05:36<01:13,  4.09s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 83%|              | 83/100 [05:40<01:06,  3.94s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 84%|             | 84/100 [05:47<01:16,  4.79s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 85%|             | 85/100 [05:53<01:18,  5.20s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 86%|            | 86/100 [05:55<01:00,  4.33s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 87%|           | 87/100 [06:00<00:58,  4.49s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 88%|          | 88/100 [06:06<01:00,  5.07s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 89%|         | 89/100 [06:08<00:45,  4.10s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 90%|        | 90/100 [06:09<00:31,  3.17s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 91%|       | 91/100 [06:16<00:36,  4.09s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 92%|       | 92/100 [06:22<00:37,  4.67s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 93%|      | 93/100 [06:24<00:28,  4.10s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 94%|     | 94/100 [06:30<00:27,  4.62s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 95%|    | 95/100 [06:33<00:20,  4.19s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 96%|   | 96/100 [06:36<00:14,  3.72s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 97%|  | 97/100 [06:42<00:12,  4.32s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 98%| | 98/100 [06:44<00:07,  3.83s/trial, best loss: 2.09619277555692]\u001b[A\n",
      " 99%|| 99/100 [06:49<00:03,  3.98s/trial, best loss: 2.09619277555692]\u001b[A\n",
      "100%|| 100/100 [06:51<00:00,  4.11s/trial, best loss: 2.09619277555692]\u001b[A\n",
      "Best hyperparameter set for random_forest is {'max_depth': 16, 'n_estimators': 259}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('CNN Feature Accuracy')\n",
    "CNN_acc = train_and_check(cnn_features, n_components, 'CNN', y, train_idx, val_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a060af94-869f-4587-8e7c-b18d70cdcc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pixel_tqdm = tqdm(prefix='Pixel', total=len(n_components) + 1, position=0, leave=True)\n",
    "# pixel_acc = []\n",
    "# for n in n_components:\n",
    "#     pixel_tqdm.set_description(f'Computing PCA({n})')\n",
    "#     _, X = feature_extractor.get_PCA([pixel_features], n_components=n+1)\n",
    "#     pixel_acc.append(train_classifier(X[0], y, train_idx, val_idx))\n",
    "#     pixel_tqdm.update(1)\n",
    "# pixel_tqdm.set_description(f'Training calssifier')\n",
    "# pixel_acc.append(train_classifier(pixel_features, y, train_idx, val_idx))\n",
    "# pixel_tqdm.update(1)\n",
    "# pixel_tqdm.close()\n",
    "\n",
    "# print('Pose Feature Accuracy')\n",
    "# pose_acc = []\n",
    "# for n in range(n_components):\n",
    "#   _, X = feature_extractor.get_PCA([pose_features], n_components=n+1)\n",
    "#   pose_acc.append(train_classifier(X[0], y, train_idx, val_idx))\n",
    "# pose_acc.append(train_classifier(pose_features, y, train_idx, val_idx))\n",
    "\n",
    "# print('CNN Feature Accuracy')\n",
    "# CNN_acc = []\n",
    "# for n in range(n_components):\n",
    "#   _, X = feature_extractor.get_PCA([CNN_features], n_components=n+1)\n",
    "#   CNN_acc.append(train_classifier(X[0], y, train_idx, val_idx))\n",
    "# CNN_acc.append(train_classifier(CNN_features, y, train_idx, val_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "09f462eb-63da-44e9-9b7a-c95c5af014ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fc/h9494d9n6bj037jj44550zmw0000gq/T/ipykernel_57061/3480572385.py:10: MatplotlibDeprecationWarning: The 'b' parameter of grid() has been renamed 'visible' since Matplotlib 3.5; support for the old name will be dropped two minor releases later.\n",
      "  plt.grid(b=True)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the accuracy graph\n",
    "plt.figure(figsize=(15,5))\n",
    "# plt.plot(np.array(pixel_acc)*100, 'b-', label='pixel features')\n",
    "plt.plot(np.arange(5)*50, np.array(pose_acc)*100, 'g-', label='pose features')\n",
    "plt.plot(np.arange(5)*50, np.array(CNN_acc)*100, 'k-', label='CNN features')\n",
    "\n",
    "xtick_labels = [f'{i+1}' for i in n_components] + ['All']\n",
    "# plt.xticks(np.arange(5)*50, labels=xtick_labels)\n",
    "plt.yticks(np.linspace(0, 100, 8))\n",
    "plt.grid(b=True)\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 100])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ed5f731d-93cc-4628-8015-e70322c7e0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fc/h9494d9n6bj037jj44550zmw0000gq/T/ipykernel_26503/3480572385.py:10: MatplotlibDeprecationWarning: The 'b' parameter of grid() has been renamed 'visible' since Matplotlib 3.5; support for the old name will be dropped two minor releases later.\n",
      "  plt.grid(b=True)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the accuracy graph\n",
    "plt.figure(figsize=(15,5))\n",
    "# plt.plot(np.array(pixel_acc)*100, 'b-', label='pixel features')\n",
    "plt.plot(np.arange(5)*50, np.array(pose_acc)*100, 'g-', label='pose features')\n",
    "plt.plot(np.arange(5)*50, np.array(CNN_acc)*100, 'k-', label='CNN features')\n",
    "\n",
    "xtick_labels = [f'{i+1}' for i in n_components] + ['All']\n",
    "# plt.xticks(np.arange(5)*50, labels=xtick_labels)\n",
    "plt.yticks(np.linspace(0, 100, 8))\n",
    "plt.grid(b=True)\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 100])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b632be10-fc41-43af-8321-2c184671b3bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
